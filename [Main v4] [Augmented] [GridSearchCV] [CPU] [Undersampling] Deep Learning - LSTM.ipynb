{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9576fde0",
   "metadata": {
    "id": "9576fde0"
   },
   "source": [
    "# BREATHING WAVE\n",
    "## DEEP LEARNING - LSTM\n",
    "### 04 March 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cfa282",
   "metadata": {
    "id": "07cfa282"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(\"breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8bf54a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa8bf54a",
    "outputId": "f4f08ec0-c57c-4ca4-c131-af36d583eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X have a null? \tFalse\n",
      "Y have a null? \tFalse\n"
     ]
    }
   ],
   "source": [
    "# Check if the data do not have any NULL \n",
    "print(\"X have a null? \\t{}\".format(X.isnull().values.any()))\n",
    "print(\"Y have a null? \\t{}\".format(Y.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa06c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0fa06c9f",
    "outputId": "35e89335-323c-4d86-9678-f74d1acf0b10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332737</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407344</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322969</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345803</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26400 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26395 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "26396 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "26397 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "26398 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "26399 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        75        76        77  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.332737  0.391514  0.452677   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.325687  0.138731 -0.053860   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.902226  0.947940  0.996154   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.407344 -0.478218 -0.571465   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.322969  0.227050  0.130983   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26395  0.041637  0.092217  0.140510  ... -0.345803 -0.336787 -0.306774   \n",
       "26396  0.092217  0.140510  0.188025  ... -0.336787 -0.306774 -0.280607   \n",
       "26397  0.140510  0.188025  0.240939  ... -0.306774 -0.280607 -0.269843   \n",
       "26398  0.188025  0.240939  0.294399  ... -0.280607 -0.269843 -0.260062   \n",
       "26399  0.240939  0.294399  0.340346  ... -0.269843 -0.260062 -0.229981   \n",
       "\n",
       "             78        79        80        81        82        83        84  \n",
       "0      0.521407  0.595845  0.661691  0.702932  0.708613  0.682564  0.637765  \n",
       "1     -0.241691 -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654  \n",
       "2      1.035743  1.049543  1.024204  0.954716  0.844505  0.702445  0.541555  \n",
       "3     -0.684115 -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059  \n",
       "4      0.041438 -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "26395 -0.280607 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  \n",
       "26396 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  \n",
       "26397 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  \n",
       "26398 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  \n",
       "26399 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418  \n",
       "\n",
       "[26400 rows x 85 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b3592e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b3592e",
    "outputId": "14191ef1-d3ce-4982-83b9-ecf9bcf5312d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        19734\n",
       "quick          2667\n",
       "hold           2133\n",
       "deep           1066\n",
       "deep_quick      800\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8299c60",
   "metadata": {},
   "source": [
    "## Fix Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85e7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 21\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b0906",
   "metadata": {
    "id": "4c2b0906"
   },
   "source": [
    "### Program Starting\n",
    "# PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae92446",
   "metadata": {},
   "source": [
    "## Importing Imbalanced Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50e7db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.1\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e4ca3",
   "metadata": {},
   "source": [
    "## Removing Class Overlapped (removing Tomek Links)\n",
    "> **Tomek links** identify pairs of samples from different classes that are close to each other and potentially contribute to class overlap or ambiguity.\n",
    ">\n",
    "> **Conclusion** : Nothing is removed. Indicate that the data is good and there is no ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e2436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomek_links(X, Y):\n",
    "    # define the undersampling method\n",
    "    undersample = imblearn.under_sampling.TomekLinks()\n",
    "    # transform the dataset\n",
    "    return undersample.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b843bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = tomek_links(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa120e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        19734\n",
       "quick          2667\n",
       "hold           2133\n",
       "deep           1066\n",
       "deep_quick      800\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80423d",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100c8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearMiss\n",
    "def near_miss(X, Y, version, neighbors=3):\n",
    "    # define the undersampling method\n",
    "    undersample = imblearn.under_sampling.NearMiss(version=version, n_neighbors=3)\n",
    "    # transform the dataset\n",
    "    return undersample.fit_resample(X, Y)\n",
    "\n",
    "# RandomUnderSample\n",
    "labels = {\n",
    "    \"normal\" : 800,\n",
    "    \"quick\" : 800,\n",
    "    \"hold\" : 800,\n",
    "    \"deep\" : 800,\n",
    "    \"deep_quick\" : 800\n",
    "}\n",
    "\n",
    "def rus(X, Y, strategy=labels):\n",
    "    # define the undersampling method\n",
    "    undersample = imblearn.under_sampling.RandomUnderSampler(sampling_strategy=strategy)\n",
    "    # transform the dataset\n",
    "    return undersample.fit_resample(X, Y)\n",
    "\n",
    "## CNN (CondensedNearestNeighbour) error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad2e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep          800\n",
       "deep_quick    800\n",
       "hold          800\n",
       "normal        800\n",
       "quick         800\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = rus(X, Y)\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45593d8",
   "metadata": {},
   "source": [
    "## Augmented Data (UP & DOWN 0.01)\n",
    "### Current Shape now  : 26400 x 3 = 79200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "072ba82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine X and Y first\n",
    "df = pd.concat([X, Y], axis=1)\n",
    "\n",
    "# data augmentation\n",
    "up = df\n",
    "down = df\n",
    "up.iloc[:, :-1] += 0.01   # increase value by 0.01\n",
    "down.iloc[:, :-1] -= 0.01 # decrease value by 0.01\n",
    "df = pd.concat([df, up, down], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a083be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.268313</td>\n",
       "      <td>-0.173284</td>\n",
       "      <td>-0.069770</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.188498</td>\n",
       "      <td>0.347947</td>\n",
       "      <td>0.507962</td>\n",
       "      <td>0.658035</td>\n",
       "      <td>0.796925</td>\n",
       "      <td>0.922728</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.354905</td>\n",
       "      <td>-1.393633</td>\n",
       "      <td>-1.390611</td>\n",
       "      <td>-1.348206</td>\n",
       "      <td>-1.296693</td>\n",
       "      <td>-1.250288</td>\n",
       "      <td>-1.212452</td>\n",
       "      <td>-1.186786</td>\n",
       "      <td>-1.179858</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.040052</td>\n",
       "      <td>-0.043108</td>\n",
       "      <td>-0.044297</td>\n",
       "      <td>-0.042844</td>\n",
       "      <td>-0.042370</td>\n",
       "      <td>-0.042329</td>\n",
       "      <td>-0.040341</td>\n",
       "      <td>-0.037264</td>\n",
       "      <td>-0.033991</td>\n",
       "      <td>-0.030304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023365</td>\n",
       "      <td>-0.021366</td>\n",
       "      <td>-0.018063</td>\n",
       "      <td>-0.013189</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>-0.001877</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230526</td>\n",
       "      <td>0.108867</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>-0.164305</td>\n",
       "      <td>-0.300901</td>\n",
       "      <td>-0.424737</td>\n",
       "      <td>-0.529279</td>\n",
       "      <td>-0.612703</td>\n",
       "      <td>-0.677537</td>\n",
       "      <td>-0.723174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.227252</td>\n",
       "      <td>-0.370599</td>\n",
       "      <td>-0.497504</td>\n",
       "      <td>-0.605621</td>\n",
       "      <td>-0.700073</td>\n",
       "      <td>-0.786514</td>\n",
       "      <td>-0.862373</td>\n",
       "      <td>-0.932655</td>\n",
       "      <td>-0.993687</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.024466</td>\n",
       "      <td>-1.187201</td>\n",
       "      <td>-1.347571</td>\n",
       "      <td>-1.492364</td>\n",
       "      <td>-1.615470</td>\n",
       "      <td>-1.723598</td>\n",
       "      <td>-1.823874</td>\n",
       "      <td>-1.915847</td>\n",
       "      <td>-1.995332</td>\n",
       "      <td>-2.060951</td>\n",
       "      <td>...</td>\n",
       "      <td>1.152974</td>\n",
       "      <td>1.162546</td>\n",
       "      <td>1.170266</td>\n",
       "      <td>1.172485</td>\n",
       "      <td>1.162577</td>\n",
       "      <td>1.143522</td>\n",
       "      <td>1.119604</td>\n",
       "      <td>1.089960</td>\n",
       "      <td>1.049195</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.428839</td>\n",
       "      <td>-0.332615</td>\n",
       "      <td>-0.248961</td>\n",
       "      <td>-0.176027</td>\n",
       "      <td>-0.112658</td>\n",
       "      <td>-0.059278</td>\n",
       "      <td>-0.004777</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.138137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361313</td>\n",
       "      <td>-0.368767</td>\n",
       "      <td>-0.370436</td>\n",
       "      <td>-0.370003</td>\n",
       "      <td>-0.369832</td>\n",
       "      <td>-0.372933</td>\n",
       "      <td>-0.381992</td>\n",
       "      <td>-0.396091</td>\n",
       "      <td>-0.413242</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>0.121465</td>\n",
       "      <td>0.146261</td>\n",
       "      <td>0.167992</td>\n",
       "      <td>0.169967</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.107878</td>\n",
       "      <td>0.083989</td>\n",
       "      <td>0.088344</td>\n",
       "      <td>0.112372</td>\n",
       "      <td>0.124531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443562</td>\n",
       "      <td>0.315667</td>\n",
       "      <td>0.188570</td>\n",
       "      <td>0.068180</td>\n",
       "      <td>-0.036559</td>\n",
       "      <td>-0.113396</td>\n",
       "      <td>-0.166452</td>\n",
       "      <td>-0.216866</td>\n",
       "      <td>-0.276723</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>-0.160531</td>\n",
       "      <td>-0.229866</td>\n",
       "      <td>-0.293130</td>\n",
       "      <td>-0.346173</td>\n",
       "      <td>-0.385350</td>\n",
       "      <td>-0.411390</td>\n",
       "      <td>-0.423413</td>\n",
       "      <td>-0.417905</td>\n",
       "      <td>-0.393790</td>\n",
       "      <td>-0.353185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076072</td>\n",
       "      <td>0.092789</td>\n",
       "      <td>0.108863</td>\n",
       "      <td>0.121987</td>\n",
       "      <td>0.128518</td>\n",
       "      <td>0.130138</td>\n",
       "      <td>0.130045</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.141146</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>-0.253933</td>\n",
       "      <td>-0.273959</td>\n",
       "      <td>-0.273578</td>\n",
       "      <td>-0.278892</td>\n",
       "      <td>-0.300258</td>\n",
       "      <td>-0.324619</td>\n",
       "      <td>-0.332424</td>\n",
       "      <td>-0.325497</td>\n",
       "      <td>-0.306345</td>\n",
       "      <td>-0.272196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020242</td>\n",
       "      <td>0.039997</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>-0.016089</td>\n",
       "      <td>-0.075329</td>\n",
       "      <td>-0.124937</td>\n",
       "      <td>-0.142297</td>\n",
       "      <td>-0.126571</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>0.077422</td>\n",
       "      <td>0.070160</td>\n",
       "      <td>0.052233</td>\n",
       "      <td>0.036485</td>\n",
       "      <td>0.034710</td>\n",
       "      <td>0.042757</td>\n",
       "      <td>0.044001</td>\n",
       "      <td>0.029344</td>\n",
       "      <td>-0.005060</td>\n",
       "      <td>-0.058217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468333</td>\n",
       "      <td>-0.373065</td>\n",
       "      <td>-0.295179</td>\n",
       "      <td>-0.230432</td>\n",
       "      <td>-0.175512</td>\n",
       "      <td>-0.134452</td>\n",
       "      <td>-0.110760</td>\n",
       "      <td>-0.101800</td>\n",
       "      <td>-0.100119</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>-0.310529</td>\n",
       "      <td>-0.281656</td>\n",
       "      <td>-0.279568</td>\n",
       "      <td>-0.292769</td>\n",
       "      <td>-0.307962</td>\n",
       "      <td>-0.310083</td>\n",
       "      <td>-0.308204</td>\n",
       "      <td>-0.323142</td>\n",
       "      <td>-0.351986</td>\n",
       "      <td>-0.370418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480921</td>\n",
       "      <td>0.538970</td>\n",
       "      <td>0.575108</td>\n",
       "      <td>0.614939</td>\n",
       "      <td>0.665803</td>\n",
       "      <td>0.702511</td>\n",
       "      <td>0.702153</td>\n",
       "      <td>0.669537</td>\n",
       "      <td>0.613689</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.268313 -0.173284 -0.069770  0.047600  0.188498  0.347947  0.507962   \n",
       "1     -0.040052 -0.043108 -0.044297 -0.042844 -0.042370 -0.042329 -0.040341   \n",
       "2      0.230526  0.108867 -0.024490 -0.164305 -0.300901 -0.424737 -0.529279   \n",
       "3     -1.024466 -1.187201 -1.347571 -1.492364 -1.615470 -1.723598 -1.823874   \n",
       "4     -0.428839 -0.332615 -0.248961 -0.176027 -0.112658 -0.059278 -0.004777   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "11995  0.121465  0.146261  0.167992  0.169967  0.144068  0.107878  0.083989   \n",
       "11996 -0.160531 -0.229866 -0.293130 -0.346173 -0.385350 -0.411390 -0.423413   \n",
       "11997 -0.253933 -0.273959 -0.273578 -0.278892 -0.300258 -0.324619 -0.332424   \n",
       "11998  0.077422  0.070160  0.052233  0.036485  0.034710  0.042757  0.044001   \n",
       "11999 -0.310529 -0.281656 -0.279568 -0.292769 -0.307962 -0.310083 -0.308204   \n",
       "\n",
       "              7         8         9  ...        76        77        78  \\\n",
       "0      0.658035  0.796925  0.922728  ... -1.354905 -1.393633 -1.390611   \n",
       "1     -0.037264 -0.033991 -0.030304  ... -0.023365 -0.021366 -0.018063   \n",
       "2     -0.612703 -0.677537 -0.723174  ... -0.227252 -0.370599 -0.497504   \n",
       "3     -1.915847 -1.995332 -2.060951  ...  1.152974  1.162546  1.170266   \n",
       "4      0.053416  0.101563  0.138137  ... -0.361313 -0.368767 -0.370436   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11995  0.088344  0.112372  0.124531  ...  0.443562  0.315667  0.188570   \n",
       "11996 -0.417905 -0.393790 -0.353185  ...  0.076072  0.092789  0.108863   \n",
       "11997 -0.325497 -0.306345 -0.272196  ...  0.020242  0.039997  0.042551   \n",
       "11998  0.029344 -0.005060 -0.058217  ... -0.468333 -0.373065 -0.295179   \n",
       "11999 -0.323142 -0.351986 -0.370418  ...  0.480921  0.538970  0.575108   \n",
       "\n",
       "             79        80        81        82        83        84  labels  \n",
       "0     -1.348206 -1.296693 -1.250288 -1.212452 -1.186786 -1.179858    deep  \n",
       "1     -0.013189 -0.007278 -0.001877  0.002095  0.004923  0.007086    deep  \n",
       "2     -0.605621 -0.700073 -0.786514 -0.862373 -0.932655 -0.993687    deep  \n",
       "3      1.172485  1.162577  1.143522  1.119604  1.089960  1.049195    deep  \n",
       "4     -0.370003 -0.369832 -0.372933 -0.381992 -0.396091 -0.413242    deep  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "11995  0.068180 -0.036559 -0.113396 -0.166452 -0.216866 -0.276723   quick  \n",
       "11996  0.121987  0.128518  0.130138  0.130045  0.132653  0.141146   quick  \n",
       "11997  0.025041 -0.016089 -0.075329 -0.124937 -0.142297 -0.126571   quick  \n",
       "11998 -0.230432 -0.175512 -0.134452 -0.110760 -0.101800 -0.100119   quick  \n",
       "11999  0.614939  0.665803  0.702511  0.702153  0.669537  0.613689   quick  \n",
       "\n",
       "[12000 rows x 86 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ab4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate again to X and Y\n",
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62ced82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep          2400\n",
       "deep_quick    2400\n",
       "hold          2400\n",
       "normal        2400\n",
       "quick         2400\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f193",
   "metadata": {
    "id": "0723f193"
   },
   "source": [
    "## Hot Encoded The Label Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0322a049",
   "metadata": {
    "id": "0322a049"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46851a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46851a41",
    "outputId": "f92ebfa5-d6db-4fb0-f31a-081e94150d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279137d",
   "metadata": {
    "id": "5279137d"
   },
   "source": [
    "## Scale The Training Data (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0513ed4",
   "metadata": {
    "id": "b0513ed4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be3b8",
   "metadata": {
    "id": "9b1be3b8"
   },
   "source": [
    "## Reshaping The Training Data to 3-Dimensional Numpy Array\n",
    "### STRUCTURE : (batch_size, timestep, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0456d564",
   "metadata": {
    "id": "0456d564"
   },
   "outputs": [],
   "source": [
    "feature = 5\n",
    "X = np.reshape(X, (X.shape[0], int(85/feature), feature))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0ca7",
   "metadata": {
    "id": "bcbc0ca7"
   },
   "source": [
    "# PART 2 : Building The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d100f8a8",
   "metadata": {
    "id": "d100f8a8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFcb5tIpis9h",
   "metadata": {
    "id": "oFcb5tIpis9h"
   },
   "source": [
    "## Creating Layer of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Model Structure\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam()\n",
    "_loss = \"categorical_crossentropy\"\n",
    "_metric = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb09d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfbb09d5",
    "outputId": "10305db0-f336-4336-d54f-4a100ebc1152"
   },
   "outputs": [],
   "source": [
    "def create_model(dropout_rate=0.2, init_mode='glorot_uniform', init_recurrent='orthogonal', init_units=60):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # first layer\n",
    "    classifier.add(LSTM(units=init_units, kernel_initializer=init_mode, recurrent_initializer=init_recurrent, return_sequences=True, input_shape=(17, 5)))\n",
    "    classifier.add(Dropout(dropout_rate))    # Ignore xx% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored) \n",
    "\n",
    "    # second layer\n",
    "    classifier.add(LSTM(units=init_units, return_sequences=True))\n",
    "    classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # third layer\n",
    "    # classifier.add(LSTM(units=20, return_sequences=True))\n",
    "    # classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # fourth layer\n",
    "    classifier.add(LSTM(units=init_units))\n",
    "    classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # last layer\n",
    "    classifier.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "    # Compile\n",
    "    classifier.compile(optimizer=_optimizer, loss=_loss, metrics=_metric)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHxGBbTjiOO",
   "metadata": {
    "id": "gYHxGBbTjiOO"
   },
   "source": [
    "# PART 3 : Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58cdf8",
   "metadata": {},
   "source": [
    "## Setting up the GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Number of CPU cores: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95556597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(model=create_model)\n",
    "\n",
    "param_grid = {\n",
    "    'epochs': [15, 20],\n",
    "    'batch_size': [32, 64],\n",
    "    'model__dropout_rate': [0.2, 0.3],\n",
    "    'model__init_mode': ['glorot_uniform', 'he_uniform'],\n",
    "    'model__init_recurrent': ['glorot_uniform', 'orthogonal'],\n",
    "    'model__init_units': [17, 30, 60]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=5, refit=True, n_jobs=cpu_count-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803e1b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84434c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "    grid_result = grid.fit(X, hot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748299a",
   "metadata": {},
   "source": [
    "## Summarize the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb17b2",
   "metadata": {},
   "source": [
    "## Plot The Best Estimator, Param, and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2738998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estimator\")\n",
    "print(grid_result.best_estimator_)\n",
    "print(\"Best Param\")\n",
    "print(grid_result.best_params_)\n",
    "print(\"Best Score\")\n",
    "print(grid_result.best_score_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yehFnOBDjZcJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
