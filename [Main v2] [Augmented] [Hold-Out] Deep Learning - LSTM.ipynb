{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9576fde0",
   "metadata": {
    "id": "9576fde0"
   },
   "source": [
    "# BREATHING WAVE\n",
    "## DEEP LEARNING - LSTM\n",
    "### 04 March 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cfa282",
   "metadata": {
    "id": "07cfa282"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(\"breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1423428f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26400 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26395 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "26396 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "26397 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "26398 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "26399 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        76        77        78  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.391514  0.452677  0.521407   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.138731 -0.053860 -0.241691   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.947940  0.996154  1.035743   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.478218 -0.571465 -0.684115   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.227050  0.130983  0.041438   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26395  0.041637  0.092217  0.140510  ... -0.336787 -0.306774 -0.280607   \n",
       "26396  0.092217  0.140510  0.188025  ... -0.306774 -0.280607 -0.269843   \n",
       "26397  0.140510  0.188025  0.240939  ... -0.280607 -0.269843 -0.260062   \n",
       "26398  0.188025  0.240939  0.294399  ... -0.269843 -0.260062 -0.229981   \n",
       "26399  0.240939  0.294399  0.340346  ... -0.260062 -0.229981 -0.167654   \n",
       "\n",
       "             79        80        81        82        83        84  labels  \n",
       "0      0.595845  0.661691  0.702932  0.708613  0.682564  0.637765    deep  \n",
       "1     -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654    deep  \n",
       "2      1.049543  1.024204  0.954716  0.844505  0.702445  0.541555    deep  \n",
       "3     -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059    deep  \n",
       "4     -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270    deep  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "26395 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372   quick  \n",
       "26396 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958   quick  \n",
       "26397 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209   quick  \n",
       "26398 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014   quick  \n",
       "26399 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418   quick  \n",
       "\n",
       "[26400 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690d724-dc02-413f-aa5d-931dff87f81c",
   "metadata": {},
   "source": [
    "## Augmented Data (UP & DOWN 0.01)\n",
    "### Current Shape now  : 26400 x 3 = 79200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc4d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = df\n",
    "down = df\n",
    "up.iloc[:, :-1] += 0.01\n",
    "down.iloc[:, :-1] -= 0.01\n",
    "df = pd.concat([df, up, down], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f6e0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79200, 86)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8bf54a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa8bf54a",
    "outputId": "f4f08ec0-c57c-4ca4-c131-af36d583eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X have a null? \tFalse\n",
      "Y have a null? \tFalse\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "# Check if the data do not have any NULL \n",
    "print(\"X have a null? \\t{}\".format(X.isnull().values.any()))\n",
    "print(\"Y have a null? \\t{}\".format(Y.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fa06c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0fa06c9f",
    "outputId": "35e89335-323c-4d86-9678-f74d1acf0b10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332737</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407344</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322969</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79195</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345803</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79196</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79197</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79198</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79199</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79200 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "79195 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "79196 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "79197 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "79198 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "79199 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        75        76        77  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.332737  0.391514  0.452677   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.325687  0.138731 -0.053860   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.902226  0.947940  0.996154   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.407344 -0.478218 -0.571465   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.322969  0.227050  0.130983   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "79195  0.041637  0.092217  0.140510  ... -0.345803 -0.336787 -0.306774   \n",
       "79196  0.092217  0.140510  0.188025  ... -0.336787 -0.306774 -0.280607   \n",
       "79197  0.140510  0.188025  0.240939  ... -0.306774 -0.280607 -0.269843   \n",
       "79198  0.188025  0.240939  0.294399  ... -0.280607 -0.269843 -0.260062   \n",
       "79199  0.240939  0.294399  0.340346  ... -0.269843 -0.260062 -0.229981   \n",
       "\n",
       "             78        79        80        81        82        83        84  \n",
       "0      0.521407  0.595845  0.661691  0.702932  0.708613  0.682564  0.637765  \n",
       "1     -0.241691 -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654  \n",
       "2      1.035743  1.049543  1.024204  0.954716  0.844505  0.702445  0.541555  \n",
       "3     -0.684115 -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059  \n",
       "4      0.041438 -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "79195 -0.280607 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  \n",
       "79196 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  \n",
       "79197 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  \n",
       "79198 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  \n",
       "79199 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418  \n",
       "\n",
       "[79200 rows x 85 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b3592e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b3592e",
    "outputId": "14191ef1-d3ce-4982-83b9-ecf9bcf5312d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        59202\n",
       "quick          8001\n",
       "hold           6399\n",
       "deep           3198\n",
       "deep_quick     2400\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b0906",
   "metadata": {
    "id": "4c2b0906"
   },
   "source": [
    "### Program Starting\n",
    "# PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f193",
   "metadata": {
    "id": "0723f193"
   },
   "source": [
    "## Hot Encoded The Label Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0322a049",
   "metadata": {
    "id": "0322a049"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46851a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46851a41",
    "outputId": "f92ebfa5-d6db-4fb0-f31a-081e94150d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee49ad",
   "metadata": {},
   "source": [
    "## Extract using MFCC (if you not want, just skip this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05580da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_mfcc(df_, sr=60, n_mfcc=85):\n",
    "  df_mfcc = []\n",
    "  with tqdm(total=df_.shape[0]) as pbar: \n",
    "      for i,row in df_.iterrows():\n",
    "        pbar.update(1)\n",
    "        y = np.array(row).astype(np.float32)\n",
    "        #print(\"y : {}\".format(y))\n",
    "        #print(\"y shape: {}\".format(np.array(y).shape))\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        #print(\"mfccs before squeze : {}\".format(mfccs))\n",
    "        #print(\"mfccs before squeze : {}\".format(np.array(mfccs).shape))\n",
    "        \n",
    "        mfccs = np.squeeze(mfccs, axis=1)\n",
    "        #print(\"mfccs after squeze: {}\".format(mfccs))\n",
    "        #print(\"mfccs after squeze : {}\".format(np.array(mfccs).shape))\n",
    "        \n",
    "        df_mfcc.append([*mfccs])\n",
    "        #print(\"df_mfcc : {}\".format(df_mfcc))\n",
    "        #print(\"df_mfcc shape : {}\".format(np.array(df_mfcc).shape))\n",
    "      df_mfcc = pd.DataFrame(df_mfcc, columns=[*np.arange(0,85)])\n",
    "  return df_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_mfcc(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279137d",
   "metadata": {
    "id": "5279137d"
   },
   "source": [
    "## Scale The Training Data (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0513ed4",
   "metadata": {
    "id": "b0513ed4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be3b8",
   "metadata": {
    "id": "9b1be3b8"
   },
   "source": [
    "## Reshaping The Training Data to 3-Dimensional Numpy Array\n",
    "### STRUCTURE : (batch_size, timestep, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0456d564",
   "metadata": {
    "id": "0456d564"
   },
   "outputs": [],
   "source": [
    "timestep = 5\n",
    "X = np.reshape(X, (X.shape[0], int(85/timestep), timestep))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P5yzJzU7qvp7",
   "metadata": {
    "id": "P5yzJzU7qvp7"
   },
   "source": [
    "## Train Test Split (80% training 20% Testing)\n",
    "### REMEMBER : seed must same (random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "QIpR2SpYqxYh",
   "metadata": {
    "id": "QIpR2SpYqxYh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, hot_y, test_size=.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0ca7",
   "metadata": {
    "id": "bcbc0ca7"
   },
   "source": [
    "# PART 2 : Building The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d100f8a8",
   "metadata": {
    "id": "d100f8a8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFcb5tIpis9h",
   "metadata": {
    "id": "oFcb5tIpis9h"
   },
   "source": [
    "## Creating Layer of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7f5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Model Structure\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam()\n",
    "_loss = \"categorical_crossentropy\"\n",
    "_metric = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbb09d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfbb09d5",
    "outputId": "10305db0-f336-4336-d54f-4a100ebc1152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 17, 60)            15840     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 17, 60)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 17, 60)            29040     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 60)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60)                29040     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,225\n",
      "Trainable params: 74,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# first layer\n",
    "classifier.add(LSTM(units=60, return_sequences=True, input_shape=(17, 5)))\n",
    "classifier.add(Dropout(0.2))    # Ignore 20% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored) \n",
    "\n",
    "# second layer\n",
    "classifier.add(LSTM(units=60, return_sequences=True))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# third layer\n",
    "# classifier.add(LSTM(units=20, return_sequences=True))\n",
    "# classifier.add(Dropout(0.2))\n",
    "\n",
    "# fourth layer\n",
    "classifier.add(LSTM(units=60))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# last layer\n",
    "classifier.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "classifier.compile(optimizer=_optimizer, loss=_loss, metrics=_metric)\n",
    "\n",
    "# Plot Summary of Model\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHxGBbTjiOO",
   "metadata": {
    "id": "gYHxGBbTjiOO"
   },
   "source": [
    "# PART 3 : Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ngysebSjIBl",
   "metadata": {
    "id": "3ngysebSjIBl"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7wCqc9xqG8l7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wCqc9xqG8l7",
    "outputId": "db6e0034-41fa-4a02-a6d8-ae353c0b1a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1980/1980 [==============================] - 64s 28ms/step - loss: 0.5928 - accuracy: 0.7919 - val_loss: 0.3808 - val_accuracy: 0.8626\n",
      "Epoch 2/15\n",
      "1980/1980 [==============================] - 38s 19ms/step - loss: 0.2959 - accuracy: 0.8941 - val_loss: 0.1825 - val_accuracy: 0.9394\n",
      "Epoch 3/15\n",
      "1980/1980 [==============================] - 42s 21ms/step - loss: 0.1598 - accuracy: 0.9478 - val_loss: 0.0864 - val_accuracy: 0.9731\n",
      "Epoch 4/15\n",
      "1980/1980 [==============================] - 43s 22ms/step - loss: 0.0976 - accuracy: 0.9705 - val_loss: 0.0764 - val_accuracy: 0.9785\n",
      "Epoch 5/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0769 - accuracy: 0.9785 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 6/15\n",
      "1980/1980 [==============================] - 45s 23ms/step - loss: 0.0649 - accuracy: 0.9818 - val_loss: 0.0423 - val_accuracy: 0.9878\n",
      "Epoch 7/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0520 - accuracy: 0.9858 - val_loss: 0.0349 - val_accuracy: 0.9899\n",
      "Epoch 8/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0484 - accuracy: 0.9865 - val_loss: 0.0355 - val_accuracy: 0.9899\n",
      "Epoch 9/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0421 - accuracy: 0.9885 - val_loss: 0.0282 - val_accuracy: 0.9920\n",
      "Epoch 10/15\n",
      "1980/1980 [==============================] - 43s 22ms/step - loss: 0.0384 - accuracy: 0.9891 - val_loss: 0.0198 - val_accuracy: 0.9949\n",
      "Epoch 11/15\n",
      "1980/1980 [==============================] - 43s 22ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.0197 - val_accuracy: 0.9944\n",
      "Epoch 12/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.0222 - val_accuracy: 0.9939\n",
      "Epoch 13/15\n",
      "1980/1980 [==============================] - 43s 22ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.0201 - val_accuracy: 0.9935\n",
      "Epoch 14/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0238 - accuracy: 0.9930 - val_loss: 0.0137 - val_accuracy: 0.9959\n",
      "Epoch 15/15\n",
      "1980/1980 [==============================] - 44s 22ms/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 0.0122 - val_accuracy: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ba20fbca0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting for training arguments (epoch, batch_size)\n",
    "ep = 15        # epoch\n",
    "bt = 32        # batch_size\n",
    "# Without Cross-Validation\n",
    "classifier.fit(X_train, Y_train, epochs=ep, batch_size=bt, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592adcf7",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "GD1YXs9fGzd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD1YXs9fGzd4",
    "outputId": "9f855f48-59ce-43d4-d11f-e4b5ecf422cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/495 [==============================] - 3s 6ms/step - loss: 0.0122 - accuracy: 0.9958\n",
      "Accuracy \t: 99.58\n",
      "Loss \t\t: 1.22\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = classifier.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "_qkQtuYLIsTg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qkQtuYLIsTg",
    "outputId": "30b8cd45-0234-48c6-a659-72a93466d297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/495 [==============================] - 4s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "t2U4bAnrIzCR",
   "metadata": {
    "id": "t2U4bAnrIzCR"
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, axis=1)\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13e6b",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Om9OAOGfplSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Om9OAOGfplSe",
    "outputId": "3e40fd9c-b99f-43b1-e20f-89472d8ead74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGwCAYAAAAXAEo1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2yUlEQVR4nO3deVxU5eIG8GcEBhAYVsEFcENFQGQTRM0N9yW1m+ZPK1SoLNe8qZmVuYHeylxSUiz1Wl41dyspDfdEBcFUzHIFk82NYZH9/P4gp0ZABgTOCzzfz2c+Nu85c+aZN4aHM+fMjEKSJAlEREQCayB3ACIiovKwrIiISHgsKyIiEh7LioiIhMeyIiIi4bGsiIhIeCwrIiISnr7cAZ5FUVER7ty5AzMzMygUCrnjEBFRBUmShIyMDDRt2hQNGpS9/1Sry+rOnTtwcHCQOwYRET2jxMRE2Nvbl7m8VpeVmZkZAODitfOa/6bSGekbyx2BiKiEDHUGnFq0Lfd3eK0uq8cv/ZmZmUGlYlk9jZF+Q7kjEBGVqbxDOTzBgoiIhMeyIiIi4bGsiIhIeCwrIiISHsuKiIiEx7IiIiLhsayIiEh4LCsiIhIey4qIiITHsiIiIuGxrIiISHgsKyIiEh7LioiIhMeyIiIi4bGsiIhIeCwrIiISHsuKiIiEx7IiIiLhsayIiEh4LCsiIhIey4qIiITHsiIiIuGxrIiISHgsKyIiEh7LioiIhMeyIiIi4bGsiIhIeCwrIiISHsuKiIiEx7LS0Z0/k/D6uDfRqmlbNLV0xHO+PRF37rxm+VvBk2Fp1Ejr0rf7gFK3JUkSXnz+JVgaNcL3+36oqYcgjLVh6+Ds5AILEyt08e2KE8dPyh1JSJwn3XCedFPb50n2slqzZg1atmwJIyMjeHt74/jx43JHKuHhg4cY0GswDAz08e3erYiKPYFFSxbA3FyltV5Av9747eZFzWX7nv+Vur2wVWuhUChqIrpwvt2+AzNnzMLsObMQFf0LunTrguFDRiAhIVHuaELhPOmG86SbujBPCkmSJLnufNu2bXjllVewZs0adO3aFWvXrsX69esRHx8PR0fHcm+vVqthbm6OW6nXoVKZVVvOj95fgNO/nMGByO/KXOet4MlIT1fjm2//+9RtXfj1IkaPGIvIkz/BuYUbvt6+CYOfH1TVkUsw0m9Y7fehi+f8e8DTywMrV6/QjHm4eWHo80OwMGSBjMnEwnnSDedJNyLPk1qthp1VE6Snp0OlUpW5nqx7VsuWLUNQUBCCg4PRvn17LF++HA4ODggLC5MzVgkR3/0IT28PjBszAW0c2qO7Xy9s+nJzifVOHDuJNg7t4ePmh2lvvo201DSt5dnZ2Xjt1Tfw8fIlsGtsV1PxhZGXl4fYc7EI6BugNR7QtzeiTp2WKZV4OE+64Tzppq7Mk2xllZeXh5iYGPTr109rvF+/fvjll19KvU1ubi7UarXWpSbcvHELX63biFatW2Hn/m0YHzwO7/77PWz9eptmnT79A7BuYxj2RuzCwqULcC4mFs8PeAG5ubmadd6b+QF8O3fCoKEDayS3aO7evYfCwkLY2tpqjdvZ2iElJUWmVOLhPOmG86SbujJP+nLd8d27d1FYWAg7O+09DDs7OyQnJ5d6m9DQUMyfP78m4mkpKiqCh7cHPlz4PgDA3cMdv13+DV+Fb8Tol18CALwwcoRmfRfX9vD06gj3tl746cBBDB0+BD98F4HjR47j6OnIGs8vmieP10mSVG+P4T0N50k3nCfd1PZ5kv0Ei4pM4Jw5c5Cenq65JCbWzMFBu8Z2cHZuqzXW1rktbifeLvM2jZs0hoOjPa5dvQ4AOH7kOG5cv4kWdk6wMWkMG5PGAIBXR4/HkL7Dqi+8QGxsrKGnp1fir7nUtNQSf/XVZ5wn3XCedFNX5km2srKxsYGenl6JvajU1NQSe1uPGRoaQqVSaV1qgp+/L/74/arW2LU/rsHe0aHM29y/dx9/3r6Dxn8dm5r+zlSciD6KY2cOay4AEPLxQqxet7L6wgtEqVTC08sTkYe09y4jDx1GZ38/mVKJh/OkG86TburKPMn2MqBSqYS3tzcOHjyIESP+fgnt4MGDGDZMrD2Nt6ZORP+eg/Dp0s8w4sVhiDkbi01fbsZnqz8FAGRmZmLpoo8xdPgQNG5sh4RbiVgwbzGsbawweNhgAMV7Z6WdVGHvYI/mLZvX6OOR09S3pyAoMBhe3p7w6+yHL8O/QmJCIoLfCJY7mlA4T7rhPOmmLsyTbGUFADNmzMArr7wCHx8f+Pv7Y926dUhISMDEiRPljFWCl48nNm/fhAUfLMLHIZ+ieQtHhHy8CKP+70UAgJ6eHuIvxmPrN9uR/jAddo3t8FyPrvhqczjMzExlTi+WkaNexP179xGyaAmSk5Lh6uaCPft3oXnz8t+qUJ9wnnTDedJNXZgnWd9nBRS/Kfg///kPkpKS4Obmhs8++wzdu3fX6bY19T6rukCU91kREf2Tru+zkr2sngXLSncsKyISUa14UzAREZEuWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDx9uQNUBSN9YxjpN5Q7htDyCnPljlArKPUM5Y5ARKXgnhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWVWxt2Do4O7nAwsQKXXy74sTxk3JHksWn//kM5oZWePffczRj5oZWpV5WfLpSs05ubi5mTp+Nlk2d0MTSHqNfGIM/b/8px0OQHX+Wnm7dF+Ho5OkLW8vGsLVsjB5de+HHAz/KHUt4Hy/5GMb6Jnhnxky5o1SIrGV17NgxDB06FE2bNoVCocCePXvkjPPMvt2+AzNnzMLsObMQFf0LunTrguFDRiAhIVHuaDUqJvocNq7fBLcOrlrjv9+6rHVZvW4VFAoFnh/xvGadd//9Hr7b9x2+2rweEYd/QGZWFl4a8X8oLCys6YchK/4sla9Zs2ZYuHgBTp4+jpOnj6Nnrx4Y+cJLiL8UL3c0YUWfjcGX6zegg7ub3FEqTNayysrKQseOHfH555/LGaPKrPxsFcZNCMT4oHFwbu+MT5Z9DHsHe4R/ES53tBqTmZmJ1wLfwMqw5bCwtNBaZtfYTuvyw/4DeK7Hc2jZqgUAID1djc0bv8aipQvRK6AnOnq4I3zDF7h0MR6Hfz5S449FTvxZKt/goYMwYNAAtGnbBm3atsH8RR/B1NQUZ06flTuakDIzMzH+1QlY88XnsLCwlDtOhclaVgMHDsSiRYvwwgsvyBmjSuTl5SH2XCwC+gZojQf07Y2oU6dlSlXz3pk2C/0H9kWvgJ5PXS81JRU/HvgJr45/WTMWdy4O+fn56N2nt2asSdMmcHFtjzNRZ6orsnD4s1RxhYWF2L7tW2RlZcGvs6/ccYQ0fcrbGDCwv9bzqzbRlztAReTm5iI3N1dzXa1Wy5hG292791BYWAhbW1utcTtbO6SkHJIpVc3asX0n4s7F4cipyHLX3bJ5K0zNTDF0+BDNWGpKKpRKJSyf2CNrZNsIKcmpVR1XWPxZ0t3FCxfRs1tv5OTkwNTUFNt2/A/tXdrLHUs427d9i9hzsTh5+oTcUSqtVp1gERoaCnNzc83FwcFB7kglKBQKreuSJJUYq4tuJ97Gu/9+D+Gb1sHIyKjc9b/e9A1GjR6p07r1ZQ6fVF9/liqibbu2OB1zCkdPHsFrbwTjtQlv4HL8ZbljCSUx8TZmvj0TG/77lU7PN1HVqrKaM2cO0tPTNZfERHEONtvYWENPTw8pKSla46lpqSX+Qq6L4s6dR1pqGnp07gWrho1g1bARThw7iS9Wr4NVw0ZaJ0j8cuIU/vj9D7w64RWtbdja2SIvLw8PHjzUGr+bdhe2do1q4mEIob7/LFWEUqlEa6fW8PbxwsKQBejg7obVq9bIHUsosedikZqahi6+3WBqqIKpoQrHjx3HmlVhMDVU1ZqTl2pVWRkaGkKlUmldRKFUKuHp5YnIQ9ovgUUeOozO/n4ypao5PXp3x6lzJ3Di7FHNxdPbE6P+byROnD0KPT09zbqbN34NDy+PEmckeXh5wMDAAId/PqwZS05KRvyly/CtR8ch6vvP0rOQJEnrUAEBvXr3RHTcGZyOOaW5ePl4YfSYl3A65pTWc1NkteqYleimvj0FQYHB8PL2hF9nP3wZ/hUSExIR/Eaw3NGqnZmZGVxcXbTGTEwawsrKUmtcrVZjz869WLR0YYltmJur8Mq4l/H+7A9gZWUFSytLvD/7Q7i6uZR7wkZdU59/lnT14dx56DegHxwc7JGRkYFvt+3AsaPHse/7PXJHE4qZmRlc3bTfRmLS0ARW1lYlxkUma1llZmbi6tWrmus3btxAXFwcrKys4OjoKGOyyhk56kXcv3cfIYuWIDkpGa5uLtizfxeaN699j6W67Ny+C5Ik4cWX/lXq8tBPFkNfXx/jxk5AzqMc9OjVHWHrt9Sav/6qCn+WypeamoqgccFITkqGubkKbh3csO/7PSXOoqS6QSFJkiTXnR85cgS9evUqMR4YGIiNGzeWe3u1Wg1zc3Ok3E8S6iVBEeUV8qURXSj1DOWOQFSvqNVq2Fk1QXp6+lN/j8u6Z9WzZ0/I2JVERFRL1KoTLIiIqH5iWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8PTlDkA1Q6lnKHeEWiE9777cEWoFlYGl3BFqBYVCIXeEOoN7VkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJ3OBly5cqXOG5w6dWqlwxAREZVGp7L67LPPdNqYQqFgWRERUZXTqaxu3LhR3TmIiIjKVOljVnl5ebhy5QoKCgqqMg8REVEJFS6r7OxsBAUFoWHDhnB1dUVCQgKA4mNVS5YsqfKAREREFS6rOXPm4Pz58zhy5AiMjIw043369MG2bduqNBwRERFQic8G3LNnD7Zt24bOnTtrfe6Vi4sLrl27VqXhiIiIgErsWaWlpcHW1rbEeFZWFj+0kYiIqkWFy6pTp074/vvvNdcfF1R4eDj8/f2rLhkREdFfKvwyYGhoKAYMGID4+HgUFBRgxYoVuHTpEk6dOoWjR49WR0YiIqrnKrxn1aVLF5w8eRLZ2dlo3bo1fvrpJ9jZ2eHUqVPw9vaujoxERFTPVerLFzt06IBNmzZVdRYiIqJSVaqsCgsLsXv3bly+fBkKhQLt27fHsGHDoK/PLx4mIqKqV+F2uXjxIoYNG4bk5GS0a9cOAPD777+jUaNG2LdvHzp06FDlIYmIqH6r8DGr4OBguLq64vbt2zh37hzOnTuHxMREuLu74/XXX6+OjEREVM9VeM/q/PnziI6OhqWlpWbM0tISixcvRqdOnao0HBEREVCJPat27dohJSWlxHhqaiqcnJyqJBQREdE/6VRWarVacwkJCcHUqVOxY8cO3L59G7dv38aOHTswffp0LF26tLrzEhFRPaSQJEkqb6UGDRpofZTS45s8Hvvn9cLCwurIWSq1Wg1zc3Ok3E+CSqWqsfuluis9777cEWoFlYFl+SsRP4JOB2q1GnZWTZCenv7U3+M6HbM6fPhwlQUjIiKqKJ3KqkePHtWdg4iIqEyVfhdvdnY2EhISkJeXpzXu7u7+zKGIiIj+qcJllZaWhvHjx+PAgQOlLq/JY1ZERFQ/VPjU9enTp+PBgweIioqCsbExIiIisGnTJrRp0wb79u2rjoxERFTPVXjPKjIyEnv37kWnTp3QoEEDNG/eHH379oVKpUJoaCgGDx5cHTmJiKgeq/CeVVZWluabgq2srJCWlgag+JPYz507V7XpiIiIUMlPsLhy5QoAwMPDA2vXrsWff/6JL774Ak2aNKnygLXN2rB1cHZygYWJFbr4dsWJ4yfljiSc+jZHp05E4ZV/jUfHVt5o3NABB/ZFaJbl5+dj4fsh6NmpD1ratEXHVt6YHDwdyXeStbYxc/K78HPtihZWTnBx7IjAkRPwx5WrmuUnj51C44YOpV5io+Nq6qFWq0ULFqOhganWpYV9K83yPbv34vlBw+DQ2BENDUxxPu5XGdOKp7Y/7yp1zCopKQkAMG/ePERERMDR0RErV65ESEhIhbYVGhqKTp06wczMDLa2thg+fLimCGujb7fvwMwZszB7zixERf+CLt26YPiQEUhISJQ7mjDq4xxlZz2Ca4f2CFm2qMSyR9mPcCHuIt5+dxoO/nIAX20Nx/U/ruPVkRO01nP37IDlaz/FsdjD2Lr3a0iShNFDx2pOaOrU2Ru/Xo/Ruowd939waO4AD++ONfI4a4KLa3tcT7ymuZyNPa1Zlp2Vjc5dOmPB4gUyJhRTXXje6fQJFk+TnZ2N3377DY6OjrCxsanQbQcMGIDRo0ejU6dOKCgowNy5c3HhwgXEx8fDxMSk3NuL9gkWz/n3gKeXB1auXqEZ83DzwtDnh2BhCJ9AgPhzVN2fYNG4oQM2bA3HwOcHlLlObHQcBnYfiugrUbB3aFbqOvEXLqO3Xz9EXTyOFq1alFien58Pzza+mPBGIGbMmV5F6f8mxydYLFqwGPv3fofTMaeeut6tm7fQvo0rTp39BR095H0rjSifYCHy807XT7Co8J7Vkxo2bAgvL68KFxUAREREYNy4cXB1dUXHjh2xYcMGJCQkICYm5llj1bi8vDzEnotFQN8ArfGAvr0Rdep0GbeqXzhHuslQZ0ChUMDcvPQnblZWNrZu3gbHFo5oat+01HV+/P4g7t+9j5deGVWdUWvctavX0MrRCe3buOLVsYG4cf2G3JGEV1eedzqdDThjxgydN7hs2bJKh0lPTwdQfOJGaXJzc5Gbm6u5rlarK31fVe3u3XsoLCzUnHzymJ2tHVJSDsmUSiyco/Ll5ORg0QeheOGl4TBTmWkt27B2Exa+H4LsrGy0aeeE7d99A6VSWep2tmzcip59eqBZGWVWG3Xy7YT1G9bBqY0TUlPTsDRkKXp1D0DM+bOwtraWO56w6srzTqeyio2N1Wljz7LLK0kSZsyYgW7dusHNza3UdUJDQzF//vxK30dNeHIOJEkS5qUAUXCOSpefn4+Jr06CVCRhyfLFJZb/a/QI9AjojpTkFIQtX4vXX34L+yJ3wcjISGu9O7eTcOTQUaz7OqymoteI/gP6aV336+wL13Yd8M1/t2Dq21NkSlV71PbnnTAfZDt58mT8+uuvOHHiRJnrzJkzR2svT61Ww8HBodqz6cLGxhp6enolvusrNS21xF809RXnqGz5+fl4/eU3kXArETt+2FZirwoAVOYqqMxVaOXUEt6+XmjX1A0H9kVgxKjhWutt3bwNltaW6D+4bw2ll4eJiQnc3Fxx9erV8leux+rK8+6Zj1lVhSlTpmDfvn04fPgw7O3ty1zP0NAQKpVK6yIKpVIJTy9PRB6K1BqPPHQYnf39ZEolFs5R6R4X1fVrN7D9u//BylrHkxckCbm5eU8MSdi6+VuMHPMvGBgYVENaceTm5uK3366gcZPGckcRWl153lX6g2yrgiRJmDJlCnbv3o0jR46gZcuWcsZ5ZlPfnoKgwGB4eXvCr7Mfvgz/CokJiQh+I1juaMKoj3OUlZmFG9duaq4n3ErExfOXYGFlgcZN7BA85g1ciLuIzTs3oqiwEKnJqQAACysLKJVK3LpxC3t37EePgO6wbmSN5DvJ+PzTNTAyNkJA/95a93XiyEkk3EzAmMDRNfkQa8ScWe9h0JCBcHBwKD5mFfofZKgz8PIrYwEA9+/fR2LCbc1ba/74/XcAgF1jOzRubCdbbhHUheedrGU1adIkbNmyBXv37oWZmRmSk4vfCGlubg5jY2M5o1XKyFEv4v69+whZtATJSclwdXPBnv270Ly5o9zRhFEf5yju3K/414C/z8qbN7v4VOFRL7+Id+bOwI/fHwQABHTur3W7nRHb0bW7PwwNDRF18gzWrf4S6Q/S0cjWBp27+WF/5B40stU+C3fLpq3o1NkHbZ3bVPOjqnl//vknAl8ej3t378GmkQ18/TrhyIlIOP71s/P9/h/wRvBEzfqvjh0HAHjvgzl4/8O5ckQWRl143j3z+6ye6c7LOLi3YcMGjBs3rtzbi/Y+K6r9+E3BuuE3BeumNp3AIJcq/abg6iJjTxIRUS1SqRMsNm/ejK5du6Jp06a4desWAGD58uXYu3dvlYYjIiICKlFWYWFhmDFjBgYNGoSHDx9qPpvMwsICy5cvr+p8REREFS+rVatWITw8HHPnzoWenp5m3MfHBxcuXKjScEREREAlyurGjRvw9PQsMW5oaIisrKwqCUVERPRPFS6rli1bIi4ursT4gQMH4OLiUhWZiIiItFT4bMCZM2di0qRJyMnJgSRJOHPmDP73v/8hNDQU69evr46MRERUz1W4rMaPH4+CggLMmjUL2dnZGDNmDJo1a4YVK1Zg9Oi69655IiKS3zO9Kfju3bsoKiqS7cMQ+aZgqmp8U7Bu+KZg3fBNweWrkTcFV+YLF4mIiCqqwmXVsmXLp/61cP369WcKRERE9KQKl9X06dO1rufn5yM2NhYRERGYOXNmVeUiIiLSqHBZTZs2rdTx1atXIzo6+pkDERERPanKvnxx4MCB2LlzZ1VtjoiISKPKymrHjh2wsrKqqs0RERFpVPhlQE9PT60TLCRJQnJyMtLS0rBmzZoqDUdERARUoqyGDx+udb1BgwZo1KgRevbsCWdn56rKRUREpFGhsiooKECLFi3Qv39/NG7cuLoyERERaanQMSt9fX28+eabyM3Nra48REREJVT4BAs/Pz/ExsZWRxYiIqJSVfiY1VtvvYV///vfuH37Nry9vWFiYqK13N3dvcrCERERARX4INsJEyZg+fLlsLCwKLkRhQKSJEGhUGi+5r4m8INsqarxg2x1ww+y1Q0/yLZ8un6Qrc5lpaenh6SkJDx69Oip6zVv3rxiSZ8By4qqGstKNywr3bCsylfln7r+uNNqsoyIiIiACp5gwb8SiIhIDhU6waJt27blFtb9+3wZhYiIqlaFymr+/PkwNzevrixERESlqlBZjR49WravsCciovpL52NWPF5FRERy0bmsdDzDnYiIqMrp/DJgUVFRdeYgIiIqU4U/bomoLjNX8gtEdWE8oK3cEWqFRxG/yx2hzqiybwomIiKqLiwrIiISHsuKiIiEx7IiIiLhsayIiEh4LCsiIhIey4qIiITHsiIiIuGxrIiISHgsKyIiEh7LioiIhMeyIiIi4bGsiIhIeCwrIiISHsuKiIiEx7IiIiLhsayIiEh4LCsiIhIey4qIiITHsiIiIuGxrIiISHgsKyIiEh7LioiIhMeyIiIi4bGsiIhIeCwrIiISHsuKiIiEx7IiIiLhsayIiEh4LCsiIhIey4qIiITHsqpia8PWwdnJBRYmVuji2xUnjp+UO5JwOEcV8/GSj2Gsb4J3ZsyUO0rVeZALxN0DjiUBh/4EUh9pL099BJy7Cxz9a3lGXslt5BYCF+8XbyPyDnA6FUh5Yjs3MoCzacXLj9wpPcuVh8W3/flPICq1Sh6eaE4cO4F/DXsRLR1aw1jfBPv27pc7UoXJWlZhYWFwd3eHSqWCSqWCv78/Dhw4IGekZ/Lt9h2YOWMWZs+ZhajoX9ClWxcMHzICCQmJckcTBueoYqLPxuDL9RvQwd1N7ihVq1ACTA0AZ4uyl1soASdV2du49ADILgA6WgOdbYFGRsCF+4D6H8VWJAG2xoC9ydPzNG0I2BlX+GHUFllZWejg3gGfrVwmd5RKk7Ws7O3tsWTJEkRHRyM6Ohq9e/fGsGHDcOnSJTljVdrKz1Zh3IRAjA8aB+f2zvhk2cewd7BH+BfhckcTBudId5mZmRj/6gSs+eJzWFhYyh2natkYFReRbRkF0aQh0EoFWBmWvY30PMDBFDBXAg31i9c3UAAZ+X+v01oFNDcFTPXL3k47i+LtGD9lnVqu/8D++GjhPAwfMUzuKJUma1kNHToUgwYNQtu2bdG2bVssXrwYpqamiIqKkjNWpeTl5SH2XCwC+gZojQf07Y2oU6dlSiUWzlHFTJ/yNgYM7I/efXrLHUVMFkogJRvILwIkCUjOBooAWD6l4KjWEuZPicLCQnz77bfIysqCv79/qevk5uYiNzdXc12tVtdUvHLdvXsPhYWFsLW11Rq3s7VDSsohmVKJhXOku+3bvkXsuVicPH1C7iji6mBV/LLf0SRAAaCBAnC3Kt7LojpH9v+rFy5cgL+/P3JycmBqaordu3fDxcWl1HVDQ0Mxf/78Gk5YMQqFQuu6JEklxuo7ztHTJSbexsy3Z2L/gX0wMjKSO464rqqL96q8rAEDPSDtUXF5+TQqPh5GdYrsZwO2a9cOcXFxiIqKwptvvonAwEDEx8eXuu6cOXOQnp6uuSQminNQ3sbGGnp6ekhJSdEaT01LLbEnUV9xjnQTey4Wqalp6OLbDaaGKpgaqnD82HGsWRUGU0MVCgsL5Y4ov+wC4HYW4GIJWBkBZgbFx6xUSiAxU+50VA1kLyulUgknJyf4+PggNDQUHTt2xIoVK0pd19DQUHPm4OOLKJRKJTy9PBF5KFJrPPLQYXT295MplVg4R7rp1bsnouPO4HTMKc3Fy8cLo8e8hNMxp6Cnpyd3RPkVScX/coe83pD9ZcAnSZKkdVyqNpn69hQEBQbDy9sTfp398GX4V0hMSETwG8FyRxMG56h8ZmZmcHVz1RozaWgCK2urEuO1VkER8Kjg7+uPCovfS2XQADDSL355L6cAyC0qXp7117pKPcBQr/i4lLEecPkh0Ma8+HZpj4D7uYCH9d/bzSn4a1uFgIS/369lrA/o//W3enYBUFgE5BUWl+DjdUwMio+D1QGZmZm4dvWa5vrNGzdxPu48LK2s4OjoIGMy3claVu+99x4GDhwIBwcHZGRkYOvWrThy5AgiIiLkjFVpI0e9iPv37iNk0RIkJyXD1c0Fe/bvQvPmjnJHEwbniAAA6vziN/0+9kd68b9NGgKulsXFE//w7+UXHxT/29Ks+HT0BgrA06b4dufvAQUS0FCv+LY2/zjOdy0DSMr++/rptOJ/vWz+Pi0+/gHwMK/kOl3t6szp7Oeiz6F/n4Ga67PfeRcA8PKrYxH+1Tq5YlWIQpIkSa47DwoKws8//4ykpCSYm5vD3d0ds2fPRt++fXW6vVqthrm5OVLuJwn1kiBRXWc8oK3cEWqFRxG/yx1BeGq1GnZWTZCenv7U3+Oy/tnw5Zdfynn3RERUS8h+ggUREVF5WFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDx9uQMQUe3zKOJ3uSPUCndzkuWOILyMnAyd1uOeFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZVbG3YOjg7ucDCxApdfLvixPGTckcSDudIN5ynp1v3RTg6efrC1rIxbC0bo0fXXvjxwI9yx6p2USfOYPzI1+Dt5A8H09aI2P9TiXX++O0qxo96HS5NO8K5sTue7/Uv/Jl4R7M8NzcXH/z7I7g7+qCtrRvGj3odSX8maZYn3rqNd956F11ce8DJxgVdO/TCp4uWIy8vr0YeY2mEKavQ0FAoFApMnz5d7iiV9u32HZg5YxZmz5mFqOhf0KVbFwwfMgIJCYlyRxMG50g3nKfyNWvWDAsXL8DJ08dx8vRx9OzVAyNfeAnxl+LljlatHmVno72bMxZ9+lGpy29ev4UX+r0Ep7atsP3AFvx46jtMmz0ZhoZKzTofzVqEiP0HsXrTCuw6uA3ZmVkY9+JrKCwsBABc/f0aioqKELpyEX4+G4F5S+bi6y+3YOlHn9TEQyyVQpIkSbZ7/8vZs2cxatQoqFQq9OrVC8uXL9fpdmq1Gubm5ki5nwSVSlW9IXXwnH8PeHp5YOXqFZoxDzcvDH1+CBaGLJAxmTg4R7rhPFVO00b2CFm6GOMmBModBQBwNye5WrfvYNoa4f8Lw4Ch/TRjbwVOhYGBAVas/7TU26jTM+DRohOWh3+C518cAgBITkqBX7tu2LTrS/Ts073U232xfB02r9+CkxePVOljyFBnwKWpB9LT05/6e1z2PavMzEyMHTsW4eHhsLS0lDtOpeXl5SH2XCwC+gZojQf07Y2oU6dlSiUWzpFuOE8VV1hYiO3bvkVWVhb8OvvKHUc2RUVFiPzxCFo6tcDYYePg0aIThvZ8QeulwguxF5Cfn4/uAc9pxho3sUM7l7aIiTpX5rbV6RkwtzSv1vxPI3tZTZo0CYMHD0afPn3KXTc3NxdqtVrrIoq7d++hsLAQtra2WuN2tnZISUmRKZVYOEe64Tzp7uKFi7Axt4V5Q0tMfWsatu34H9q7tJc7lmzupt1DVmYW1ixbi559u+ObfZswYGg/vD7mLZw6XvyHTmrqXSiVSlg8UTw2tjZIS0krdbs3r9/CxrX/xStBY6r9MZRFX7Z7BrB161bExMQgOjpap/VDQ0Mxf/78ak71bBQKhdZ1SZJKjNV3nCPdcJ7K17ZdW5yOOYWHD9OxZ9cevDbhDfwUGVFvC6uoqAgA0G9wH7w2eQIAwNXdBdGnz+HrL7fA/zm/sm9cxs9XclIKXhkxHoNHDML/jXupWnLrQrY9q8TEREybNg3ffPMNjIyMdLrNnDlzkJ6errkkJopzsNnGxhp6enol/vJNTUst8RdyfcU50g3nSXdKpRKtnVrD28cLC0MWoIO7G1avWiN3LNlYWVtCX18fbZydtMbbtGuNO7eLzwa0tbVBXl4eHj5I11rnbto92NjaaI0lJ6XgpUFj4e3riaWrFldv+HLIVlYxMTFITU2Ft7c39PX1oa+vj6NHj2LlypXQ19fXnJXyT4aGhlCpVFoXUSiVSnh6eSLyUKTWeOShw+js/5S/ZuoRzpFuOE+VJ0kScnNz5Y4hG6VSiY7eHXD9jxta49f/uIFmDs0AAB08O8DAwADHI09olqckp+JK/O/w7uylGUu6k4xRA8fAraMrPv3iP2jQQN6jRrK9DBgQEIALFy5ojY0fPx7Ozs6YPXs29PT0ZEpWeVPfnoKgwGB4eXvCr7Mfvgz/CokJiQh+I1juaMLgHOmG81S+D+fOQ78B/eDgYI+MjAx8u20Hjh09jn3f75E7WrXKyszCzeu3NNcTb93GpV/jYWFpgWYOTfHGtNcwKXAa/Lp2gn/3zjh68BgOHYjE9gNbAAAqczO89OpILHwvBJZWFrCwssCi90Lh7NoOz/XqCqB4j2rUwDFoZt8U74fMwb279zX3Z2vXqGYf8F9kKyszMzO4ublpjZmYmMDa2rrEeG0xctSLuH/vPkIWLUFyUjJc3VywZ/8uNG/uKHc0YXCOdMN5Kl9qaiqCxgUjOSkZ5uYquHVww77v95Q4i7Ku+fXcBYwaNFZzfcG7xS/PvTj2BXy29mMMfL4/QlYsxOpPw/DhzAVo3aYV1n6zGr5dfDS3mbf0fejr6+HNwKnIeZSDbj27YNna/2h2Eo79fBw3r93CzWu34Nu2q9b9J2Zeq4FHWZIQ77N6rGfPnvDw8Ki177MiIvqn6n6fVV2g6/usZD0b8ElHjhyROwIREQlI9vdZERERlYdlRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCY9lRUREwmNZERGR8FhWREQkPJYVEREJT1/uAM9CkiQAQIY6Q+YkREQlZeTwd1N5MjMyAfz9+7wstbqsMjKKfxCcWrSVOQkRET2LjIwMmJubl7lcIZVXZwIrKirCnTt3YGZmBoVCIXccAIBarYaDgwMSExOhUqnkjiMszpNuOE+64TzpRsR5kiQJGRkZaNq0KRo0KPvIVK3es2rQoAHs7e3ljlEqlUolzA+DyDhPuuE86YbzpBvR5ulpe1SP8QQLIiISHsuKiIiEx7KqYoaGhpg3bx4MDQ3ljiI0zpNuOE+64TzppjbPU60+wYKIiOoH7lkREZHwWFZERCQ8lhUREQmPZUVERMJjWVWxNWvWoGXLljAyMoK3tzeOHz8udyShHDt2DEOHDkXTpk2hUCiwZ88euSMJKTQ0FJ06dYKZmRlsbW0xfPhwXLlyRe5YQgkLC4O7u7vmDa7+/v44cOCA3LGEFxoaCoVCgenTp8sdpUJYVlVo27ZtmD59OubOnYvY2Fg899xzGDhwIBISEuSOJoysrCx07NgRn3/+udxRhHb06FFMmjQJUVFROHjwIAoKCtCvXz9kZWXJHU0Y9vb2WLJkCaKjoxEdHY3evXtj2LBhuHTpktzRhHX27FmsW7cO7u7uckepOImqjK+vrzRx4kStMWdnZ+ndd9+VKZHYAEi7d++WO0atkJqaKgGQjh49KncUoVlaWkrr16+XO4aQMjIypDZt2kgHDx6UevToIU2bNk3uSBXCPasqkpeXh5iYGPTr109rvF+/fvjll19kSkV1RXp6OgDAyspK5iRiKiwsxNatW5GVlQV/f3+54whp0qRJGDx4MPr06SN3lEqp1R9kK5K7d++isLAQdnZ2WuN2dnZITk6WKRXVBZIkYcaMGejWrRvc3NzkjiOUCxcuwN/fHzk5OTA1NcXu3bvh4uIidyzhbN26FTExMYiOjpY7SqWxrKrYk19VIkmSMF9fQrXT5MmT8euvv+LEiRNyRxFOu3btEBcXh4cPH2Lnzp0IDAzE0aNHWVj/kJiYiGnTpuGnn36CkZGR3HEqjWVVRWxsbKCnp1diLyo1NbXE3haRrqZMmYJ9+/bh2LFjwn4djpyUSiWcnJwAAD4+Pjh79ixWrFiBtWvXypxMHDExMUhNTYW3t7dmrLCwEMeOHcPnn3+O3Nxc6OnpyZhQNzxmVUWUSiW8vb1x8OBBrfGDBw+iS5cuMqWi2kqSJEyePBm7du1CZGQkWrZsKXekWkGSJOTm5sodQygBAQG4cOEC4uLiNBcfHx+MHTsWcXFxtaKoAO5ZVakZM2bglVdegY+PD/z9/bFu3TokJCRg4sSJckcTRmZmJq5evaq5fuPGDcTFxcHKygqOjo4yJhPLpEmTsGXLFuzduxdmZmaaPXZzc3MYGxvLnE4M7733HgYOHAgHBwdkZGRg69atOHLkCCIiIuSOJhQzM7MSxzpNTExgbW1du46BynsyYt2zevVqqXnz5pJSqZS8vLx4qvETDh8+LAEocQkMDJQ7mlBKmyMA0oYNG+SOJowJEyZonmuNGjWSAgICpJ9++knuWLVCbTx1nV8RQkREwuMxKyIiEh7LioiIhMeyIiIi4bGsiIhIeCwrIiISHsuKiIiEx7IiIiLhsayIiEh4LCuiZ/TRRx/Bw8NDc33cuHEYPnx4jee4efMmFAoF4uLiylynRYsWWL58uc7b3LhxIywsLJ45m0KhwJ49e555O1R/sayoTho3bhwUCgUUCgUMDAzQqlUrvPPOOzXytfArVqzAxo0bdVpXl4IhIn6QLdVhAwYMwIYNG5Cfn4/jx48jODgYWVlZCAsLK7Fufn4+DAwMquR+zc3Nq2Q7RPQ37llRnWVoaIjGjRvDwcEBY8aMwdixYzUvRT1+6e6rr75Cq1atYGhoCEmSkJ6ejtdffx22trZQqVTo3bs3zp8/r7XdJUuWwM7ODmZmZggKCkJOTo7W8idfBiwqKsLSpUvh5OQEQ0NDODo6YvHixQCg+eoPT09PKBQK9OzZU3O7DRs2oH379jAyMoKzszPWrFmjdT9nzpyBp6cnjIyM4OPjg9jY2ArP0bJly9ChQweYmJjAwcEBb731FjIzM0ust2fPHrRt2xZGRkbo27cvEhMTtZbv378f3t7eMDIyQqtWrTB//nwUFBRUOA9RWVhWVG8YGxsjPz9fc/3q1avYvn07du7cqXkZbvDgwUhOTsYPP/yAmJgYeHl5ISAgAPfv3wcAbN++HfPmzcPixYsRHR2NJk2alCiRJ82ZMwdLly7FBx98gPj4eGzZskXzhZxnzpwBABw6dAhJSUnYtWsXACA8PBxz587F4sWLcfnyZYSEhOCDDz7Apk2bAABZWVkYMmQI2rVrh5iYGHz00Ud45513KjwnDRo0wMqVK3Hx4kVs2rQJkZGRmDVrltY62dnZWLx4MTZt2oSTJ09CrVZj9OjRmuU//vgjXn75ZUydOhXx8fFYu3YtNm7cqClkoioh86e+E1WLwMBAadiwYZrrp0+flqytraVRo0ZJkiRJ8+bNkwwMDKTU1FTNOj///LOkUqmknJwcrW21bt1aWrt2rSRJkuTv7y9NnDhRa7mfn5/UsWPHUu9brVZLhoaGUnh4eKk5b9y4IQGQYmNjtcYdHBykLVu2aI0tXLhQ8vf3lyRJktauXStZWVlJWVlZmuVhYWGlbuufmjdvLn322WdlLt++fbtkbW2tub5hwwYJgBQVFaUZu3z5sgRAOn36tCRJkvTcc89JISEhWtvZvHmz1KRJE811ANLu3bvLvF+i8vCYFdVZ3333HUxNTVFQUID8/HwMGzYMq1at0ixv3rw5GjVqpLkeExODzMxMWFtba23n0aNHuHbtGgDg8uXLJb5M09/fH4cPHy41w+XLl5Gbm4uAgACdc6elpSExMRFBQUF47bXXNOMFBQWa42GXL19Gx44d0bBhQ60cFXX48GGEhIQgPj4earUaBQUFyMnJQVZWFkxMTAAA+vr68PHx0dzG2dkZFhYWuHz5Mnx9fRETE4OzZ89q7UkVFhYiJycH2dnZWhmJKotlRXVWr169EBYWBgMDAzRt2rTECRSPfxk/VlRUhCZNmuDIkSMltlXZ07cr862+RUVFAIpfCvTz89Na9vgryKUq+Bq6W7duYdCgQZg4cSIWLlwIKysrnDhxAkFBQVovlwLFp54/6fFYUVER5s+fjxdeeKHEOkZGRs+ckwhgWVEdZmJiAicnJ53X9/LyQnJyMvT19dGiRYtS12nfvj2ioqLw6quvasaioqLK3GabNm1gbGyMn3/+GcHBwSWWK5VKAMV7Io/Z2dmhWbNmuH79OsaOHVvqdl1cXLB582Y8evRIU4hPy1Ga6OhoFBQU4NNPP0WDBsWHr7dv315ivYKCAkRHR8PX1xcAcOXKFTx8+BDOzs4AiuftypUrFZproopiWRH9pU+fPvD398fw4cOxdOlStGvXDnfu3MEPP/yA4cOHw8fHB9OmTUNgYCB8fHzQrVs3fPPNN7h06RJatWpV6jaNjIwwe/ZszJo1C0qlEl27dkVaWhouXbqEoKAg2NrawtjYGBEREbC3t4eRkRHMzc3x0UcfYerUqVCpVBg4cCByc3MRHR2NBw8eYMaMGRgzZgzmzp2LoKAgvP/++7h58yY++eSTCj3e1q1bo6CgAKtWrcLQoUNx8uRJfPHFFyXWMzAwwJQpU7By5UoYGBhg8uTJ6Ny5s6a8PvzwQwwZMgQODg4YOXIkGjRogF9//RUXLlzAokWLKv4/gqg0ch80I6oOT55g8aR58+ZpnRTxmFqtlqZMmSI1bdpUMjAwkBwcHKSxY8dKCQkJmnUWL14s2djYSKamplJgYKA0a9asMk+wkCRJKiwslBYtWiQ1b95cMjAwkBwdHbVOSAgPD5ccHBykBg0aSD169NCMf/PNN5KHh4ekVColS0tLqXv37tKuXbs0y0+dOiV17NhRUiqVkoeHh7Rz584Kn2CxbNkyqUmTJpKxsbHUv39/6b///a8EQHrw4IEkScUnWJibm0s7d+6UWrVqJSmVSql3797SzZs3tbYbEREhdenSRTI2NpZUKpXk6+srrVu3TrMcPMGCnpFCkqrgxW8iIqJqxPdZERGR8FhWREQkPJYVEREJj2VFRETCY1kREZHwWFZERCQ8lhUREQmPZUVERMJjWRERkfBYVkREJDyWFRERCe//AQohWFgfyT98AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Greens)\n",
    "\n",
    "# Add labels to the plot\n",
    "tick_marks = np.arange(len(conf_matrix))\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Add values to the plot\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yehFnOBDjZcJ",
   "metadata": {
    "id": "yehFnOBDjZcJ"
   },
   "source": [
    "## Saving the model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BW3wgAyQjoF9",
   "metadata": {
    "id": "BW3wgAyQjoF9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# saving the model\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\", _optimizer)\n",
    "classifier.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vFkQEQYVj5sb",
   "metadata": {
    "id": "vFkQEQYVj5sb"
   },
   "source": [
    "# PART 4 : Testing the Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGVuh9xGmzuj",
   "metadata": {
    "id": "xGVuh9xGmzuj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# _optimizer = \"Adam\"\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\", _optimizer)\n",
    "\n",
    "# load model\n",
    "loaded_model = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cf7c1",
   "metadata": {
    "id": "1xjvuy1flJtr"
   },
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be023c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04b558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yehFnOBDjZcJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
