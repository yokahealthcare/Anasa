{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9576fde0",
   "metadata": {
    "id": "9576fde0"
   },
   "source": [
    "# BREATHING WAVE\n",
    "## DEEP LEARNING - LSTM\n",
    "### 04 March 2023\n",
    "#### V3 = with cross-validation technique included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cfa282",
   "metadata": {
    "id": "07cfa282"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Enable XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "df = pd.read_csv(\"breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8bf54a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa8bf54a",
    "outputId": "f4f08ec0-c57c-4ca4-c131-af36d583eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X have a null? \tFalse\n",
      "Y have a null? \tFalse\n"
     ]
    }
   ],
   "source": [
    "# Check if the data do not have any NULL \n",
    "print(\"X have a null? \\t{}\".format(X.isnull().values.any()))\n",
    "print(\"Y have a null? \\t{}\".format(Y.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa06c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0fa06c9f",
    "outputId": "35e89335-323c-4d86-9678-f74d1acf0b10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332737</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407344</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322969</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345803</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26400 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26395 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "26396 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "26397 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "26398 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "26399 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        75        76        77  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.332737  0.391514  0.452677   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.325687  0.138731 -0.053860   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.902226  0.947940  0.996154   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.407344 -0.478218 -0.571465   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.322969  0.227050  0.130983   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26395  0.041637  0.092217  0.140510  ... -0.345803 -0.336787 -0.306774   \n",
       "26396  0.092217  0.140510  0.188025  ... -0.336787 -0.306774 -0.280607   \n",
       "26397  0.140510  0.188025  0.240939  ... -0.306774 -0.280607 -0.269843   \n",
       "26398  0.188025  0.240939  0.294399  ... -0.280607 -0.269843 -0.260062   \n",
       "26399  0.240939  0.294399  0.340346  ... -0.269843 -0.260062 -0.229981   \n",
       "\n",
       "             78        79        80        81        82        83        84  \n",
       "0      0.521407  0.595845  0.661691  0.702932  0.708613  0.682564  0.637765  \n",
       "1     -0.241691 -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654  \n",
       "2      1.035743  1.049543  1.024204  0.954716  0.844505  0.702445  0.541555  \n",
       "3     -0.684115 -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059  \n",
       "4      0.041438 -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "26395 -0.280607 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  \n",
       "26396 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  \n",
       "26397 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  \n",
       "26398 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  \n",
       "26399 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418  \n",
       "\n",
       "[26400 rows x 85 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b3592e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b3592e",
    "outputId": "14191ef1-d3ce-4982-83b9-ecf9bcf5312d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        19734\n",
       "quick          2667\n",
       "hold           2133\n",
       "deep           1066\n",
       "deep_quick      800\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b0906",
   "metadata": {
    "id": "4c2b0906"
   },
   "source": [
    "### Program Starting\n",
    "# PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f193",
   "metadata": {
    "id": "0723f193"
   },
   "source": [
    "## Hot Encoded The Label Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0322a049",
   "metadata": {
    "id": "0322a049"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279137d",
   "metadata": {
    "id": "5279137d"
   },
   "source": [
    "## Scale The Training Data (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0513ed4",
   "metadata": {
    "id": "b0513ed4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be3b8",
   "metadata": {
    "id": "9b1be3b8"
   },
   "source": [
    "## Reshaping The Training Data to 3-Dimensional Numpy Array\n",
    "### STRUCTURE : (batch_size, timestep, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0456d564",
   "metadata": {
    "id": "0456d564"
   },
   "outputs": [],
   "source": [
    "timestep = 5\n",
    "X = np.reshape(X, (X.shape[0], int(85/timestep), timestep))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0ca7",
   "metadata": {
    "id": "bcbc0ca7"
   },
   "source": [
    "# PART 2 : Building The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d100f8a8",
   "metadata": {
    "id": "d100f8a8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFcb5tIpis9h",
   "metadata": {
    "id": "oFcb5tIpis9h"
   },
   "source": [
    "## Creating Layer of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc7f5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Model Structure\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam()\n",
    "_loss = \"categorical_crossentropy\"\n",
    "_metric = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfbb09d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfbb09d5",
    "outputId": "10305db0-f336-4336-d54f-4a100ebc1152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 17, 60)            15840     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 17, 60)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 17, 60)            29040     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 60)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60)                29040     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,225\n",
      "Trainable params: 74,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# first layer\n",
    "classifier.add(LSTM(units=60, return_sequences=True, input_shape=(17, 5)))\n",
    "classifier.add(Dropout(0.2))    # Ignore 20% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored) \n",
    "\n",
    "# second layer\n",
    "classifier.add(LSTM(units=60, return_sequences=True))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# third layer\n",
    "# classifier.add(LSTM(units=20, return_sequences=True))\n",
    "# classifier.add(Dropout(0.2))\n",
    "\n",
    "# fourth layer\n",
    "classifier.add(LSTM(units=60))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# last layer\n",
    "classifier.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "classifier.compile(optimizer=_optimizer, loss=_loss, metrics=_metric)\n",
    "\n",
    "# Plot Summary of Model\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHxGBbTjiOO",
   "metadata": {
    "id": "gYHxGBbTjiOO"
   },
   "source": [
    "# PART 3 : Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ngysebSjIBl",
   "metadata": {
    "id": "3ngysebSjIBl"
   },
   "source": [
    "## Train the Model - Cross Validation (Stratified K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7wCqc9xqG8l7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wCqc9xqG8l7",
    "outputId": "db6e0034-41fa-4a02-a6d8-ae353c0b1a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Setting for training arguments (epoch, batch_size)\n",
    "ep = 15       # epoch\n",
    "bt = 32        # batch_size\n",
    "\n",
    "# Create an instance of StratifiedKFold with the desired number of folds\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, Y)):\n",
    "    print('Fold:', fold+1)\n",
    "    X_train, Y_train = X[train_idx], hot_y[train_idx]\n",
    "    X_val, Y_val = X[val_idx], hot_y[val_idx]\n",
    "    \n",
    "\n",
    "    # Train the model on the training set\n",
    "    classifier.fit(X_train, Y_train, epochs=ep, batch_size=bt, validation_data=(X_val, Y_val))\n",
    "    # Record the evaluation metric for this fold - training data\n",
    "    history['loss'].append(classifier.history.history['loss'][-1] * 100)\n",
    "    history['accuracy'].append(classifier.history.history['accuracy'][-1] * 100)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    loss, accuracy = classifier.evaluate(X_val, Y_val, verbose=0)\n",
    "    # print('Validation Loss\\t\\t: {:.2f}%'.format(loss*100))\n",
    "    # print('Validation Accuracy\\t: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "    # Record the evaluation metric for this fold - validation data\n",
    "    history['val_loss'].append(loss*100)\n",
    "    history['val_accuracy'].append(accuracy*100)\n",
    "    \n",
    "    # saving the model\n",
    "    filename = \"{}\\\\{}\\\\{}-f{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\\\\CV\\\\StratifiedKFold\", fold+1, n_splits)\n",
    "    classifier.save(filename)\n",
    "    \n",
    "    # clear all the weight - set all weight to random number\n",
    "    classifier.set_weights([GlorotUniform(seed=21)(w.shape) for w in classifier.weights])\n",
    "\n",
    "# Calculate the mean and standard deviation of the evaluation metric across all folds\n",
    "mean_loss = np.mean(history['val_loss'], axis=0)\n",
    "std_loss = np.std(history['val_loss'], axis=0)\n",
    "mean_accuracy = np.mean(history['val_accuracy'], axis=0)\n",
    "std_accuracy = np.std(history['val_accuracy'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724a6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613cfc69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('[Lowest] Validation Loss\\t\\t\\t: {:.2f}%'.format(np.min(history['val_loss'])))\n",
    "print('[Highest] Validation Loss\\t\\t\\t: {:.2f}%'.format(np.max(history['val_loss'])))\n",
    "print('Mean Validation Loss\\t\\t\\t\\t: {:.2f}%'.format(mean_loss))\n",
    "print('Standard Deviation of Validation Loss\\t\\t: {:.2f}%'.format(std_loss))\n",
    "print()\n",
    "print('[Lowest] Validation Accuracy\\t\\t\\t: {:.2f}%'.format(np.min(history['val_accuracy'])))\n",
    "print('[Highest] Validation Accuracy\\t\\t\\t: {:.2f}%'.format(np.max(history['val_accuracy'])))\n",
    "print('Mean Validation Accuracy\\t\\t\\t: {:.2f}%'.format(mean_accuracy))\n",
    "print('Standard Deviation of Validation Accuracy\\t: {:.2f}%'.format(std_accuracy))\n",
    "print(\"\\n-----------------------------------\")\n",
    "print(\"RESULT OF PREDICTIONS - K-FOLD\")\n",
    "print(\"-----------------------------------\")\n",
    "from prettytable import PrettyTable\n",
    "  \n",
    "columns = [\"Fold\", \"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"]\n",
    "  \n",
    "myTable = PrettyTable()\n",
    "  \n",
    "# Add Columns\n",
    "myTable.add_column(columns[0], np.arange(1, n_splits+1))\n",
    "myTable.add_column(columns[1], [str(round(i, 2)) for i in history['loss']])\n",
    "myTable.add_column(columns[2], [str(round(i, 2)) for i in history['accuracy']])\n",
    "myTable.add_column(columns[3], [str(round(i, 2)) for i in history['val_loss']])\n",
    "myTable.add_column(columns[4], [str(round(i, 2)) for i in history['val_accuracy']])\n",
    "\n",
    "# sort the table by salary in descending order\n",
    "myTable.sortby = \"val_accuracy\"\n",
    "myTable.reversesort = True\n",
    "  \n",
    "print(myTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vFkQEQYVj5sb",
   "metadata": {
    "id": "vFkQEQYVj5sb"
   },
   "source": [
    "# PART 4 : Testing the Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGVuh9xGmzuj",
   "metadata": {
    "id": "xGVuh9xGmzuj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\\\\CV\\\\KFold\", \"6-f10\")\n",
    "\n",
    "# load model\n",
    "loaded_model = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cf7c1",
   "metadata": {
    "id": "1xjvuy1flJtr"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be023c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(X, hot_y)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7336463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(hot_y, axis=1)\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13e6b",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Om9OAOGfplSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Om9OAOGfplSe",
    "outputId": "3e40fd9c-b99f-43b1-e20f-89472d8ead74"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Greens)\n",
    "\n",
    "# Add labels to the plot\n",
    "tick_marks = np.arange(len(conf_matrix))\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Add values to the plot\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04b558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yehFnOBDjZcJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
