{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9576fde0",
   "metadata": {
    "id": "9576fde0"
   },
   "source": [
    "# BREATHING WAVE\n",
    "## DEEP LEARNING - LSTM\n",
    "### 04 March 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfa282",
   "metadata": {
    "id": "07cfa282"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(\"breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bf54a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa8bf54a",
    "outputId": "f4f08ec0-c57c-4ca4-c131-af36d583eedf"
   },
   "outputs": [],
   "source": [
    "# Check if the data do not have any NULL \n",
    "print(\"X have a null? \\t{}\".format(X.isnull().values.any()))\n",
    "print(\"Y have a null? \\t{}\".format(Y.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa06c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0fa06c9f",
    "outputId": "35e89335-323c-4d86-9678-f74d1acf0b10"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3592e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b3592e",
    "outputId": "14191ef1-d3ce-4982-83b9-ecf9bcf5312d"
   },
   "outputs": [],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8299c60",
   "metadata": {},
   "source": [
    "## Fix Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 21\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b0906",
   "metadata": {
    "id": "4c2b0906"
   },
   "source": [
    "### Program Starting\n",
    "# PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f193",
   "metadata": {
    "id": "0723f193"
   },
   "source": [
    "## Hot Encoded The Label Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322a049",
   "metadata": {
    "id": "0322a049"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46851a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46851a41",
    "outputId": "f92ebfa5-d6db-4fb0-f31a-081e94150d10"
   },
   "outputs": [],
   "source": [
    "hot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279137d",
   "metadata": {
    "id": "5279137d"
   },
   "source": [
    "## Scale The Training Data (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0513ed4",
   "metadata": {
    "id": "b0513ed4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be3b8",
   "metadata": {
    "id": "9b1be3b8"
   },
   "source": [
    "## Reshaping The Training Data to 3-Dimensional Numpy Array\n",
    "### STRUCTURE : (batch_size, timestep, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456d564",
   "metadata": {
    "id": "0456d564"
   },
   "outputs": [],
   "source": [
    "feature = 5\n",
    "X = np.reshape(X, (X.shape[0], int(85/feature), feature))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0ca7",
   "metadata": {
    "id": "bcbc0ca7"
   },
   "source": [
    "# PART 2 : Building The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100f8a8",
   "metadata": {
    "id": "d100f8a8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFcb5tIpis9h",
   "metadata": {
    "id": "oFcb5tIpis9h"
   },
   "source": [
    "## Creating Layer of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Model Structure\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam()\n",
    "_loss = \"categorical_crossentropy\"\n",
    "_metric = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb09d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfbb09d5",
    "outputId": "10305db0-f336-4336-d54f-4a100ebc1152"
   },
   "outputs": [],
   "source": [
    "def create_model(dropout_rate=0.2, init_mode='glorot_uniform', init_recurrent='orthogonal', init_units=60):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # first layer\n",
    "    classifier.add(LSTM(units=init_units, kernel_initializer=init_mode, recurrent_initializer=init_recurrent, return_sequences=True, input_shape=(17, 5)))\n",
    "    classifier.add(Dropout(dropout_rate))    # Ignore xx% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored) \n",
    "\n",
    "    # second layer\n",
    "    classifier.add(LSTM(units=init_units, return_sequences=True))\n",
    "    classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # third layer\n",
    "    # classifier.add(LSTM(units=20, return_sequences=True))\n",
    "    # classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # fourth layer\n",
    "    classifier.add(LSTM(units=init_units))\n",
    "    classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # last layer\n",
    "    classifier.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "    # Compile\n",
    "    classifier.compile(optimizer=_optimizer, loss=_loss, metrics=_metric)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHxGBbTjiOO",
   "metadata": {
    "id": "gYHxGBbTjiOO"
   },
   "source": [
    "# PART 3 : Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58cdf8",
   "metadata": {},
   "source": [
    "## Setting up the GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Number of CPU cores: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95556597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(model=create_model)\n",
    "\n",
    "param_grid = {\n",
    "    'epochs': [15, 20],\n",
    "    'batch_size': [32, 64],\n",
    "    'model__dropout_rate': [0.2, 0.3],\n",
    "    'model__init_mode': ['glorot_uniform', 'he_uniform'],\n",
    "    'model__init_recurrent': ['glorot_uniform', 'orthogonal'],\n",
    "    'model__init_units': [17, 30, 60]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=5, refit=True, n_jobs=cpu_count-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803e1b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84434c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "    grid_result = grid.fit(X, hot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748299a",
   "metadata": {},
   "source": [
    "## Summarize the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb17b2",
   "metadata": {},
   "source": [
    "## Plot The Best Estimator, Param, and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2738998",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estimator\")\n",
    "print(grid_result.best_estimator_)\n",
    "print(\"Best Param\")\n",
    "print(grid_result.best_params_)\n",
    "print(\"Best Score\")\n",
    "print(grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46993358",
   "metadata": {},
   "source": [
    "## Save the Result to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(GS.cv_results_)\n",
    "res.to_csv(\"GridSearch_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87658603",
   "metadata": {},
   "source": [
    "## Save the BEST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcafd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "filename = \"{}\\\\{}\\\\{}.pickle\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\\\\CV\\\\GridSearchCV\", \"best_model\")\n",
    "best_model = grid_result.best_estimator_\n",
    "\n",
    "# save the model to pickle file\n",
    "with open(filename, 'wb') as o:\n",
    "    pickle.dump(best_model, o)\n",
    "    # close the file\n",
    "    o.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592adcf7",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b748cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, hot_y, test_size=.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5438060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model to pickle file\n",
    "filename = \"{}\\\\{}\\\\{}.pickle\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\\\\CV\\\\GridSearchCV\", \"best_model\")\n",
    "with open(filename, 'rb') as o:\n",
    "    # dump information to that file\n",
    "    data = pickle.load(o)\n",
    "\n",
    "    # close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GD1YXs9fGzd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD1YXs9fGzd4",
    "outputId": "9f855f48-59ce-43d4-d11f-e4b5ecf422cc"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "score = classifier.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_qkQtuYLIsTg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qkQtuYLIsTg",
    "outputId": "30b8cd45-0234-48c6-a659-72a93466d297"
   },
   "outputs": [],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t2U4bAnrIzCR",
   "metadata": {
    "id": "t2U4bAnrIzCR"
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, axis=1)\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13e6b",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Om9OAOGfplSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Om9OAOGfplSe",
    "outputId": "3e40fd9c-b99f-43b1-e20f-89472d8ead74"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Greens)\n",
    "\n",
    "# Add labels to the plot\n",
    "tick_marks = np.arange(len(conf_matrix))\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Add values to the plot\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yehFnOBDjZcJ",
   "metadata": {
    "id": "yehFnOBDjZcJ"
   },
   "source": [
    "## Saving the model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BW3wgAyQjoF9",
   "metadata": {
    "id": "BW3wgAyQjoF9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# saving the model\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\", _optimizer)\n",
    "classifier.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vFkQEQYVj5sb",
   "metadata": {
    "id": "vFkQEQYVj5sb"
   },
   "source": [
    "# PART 4 : Testing the Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGVuh9xGmzuj",
   "metadata": {
    "id": "xGVuh9xGmzuj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\", _optimizer)\n",
    "\n",
    "# load model\n",
    "loaded_model = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cf7c1",
   "metadata": {
    "id": "1xjvuy1flJtr"
   },
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be023c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yehFnOBDjZcJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
