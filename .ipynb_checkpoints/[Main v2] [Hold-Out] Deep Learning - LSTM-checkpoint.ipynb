{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9576fde0",
   "metadata": {
    "id": "9576fde0"
   },
   "source": [
    "# BREATHING WAVE\n",
    "## DEEP LEARNING - LSTM\n",
    "### 04 March 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cfa282",
   "metadata": {
    "id": "07cfa282"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(\"breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1423428f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26400 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26395 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "26396 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "26397 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "26398 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "26399 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        76        77        78  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.391514  0.452677  0.521407   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.138731 -0.053860 -0.241691   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.947940  0.996154  1.035743   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.478218 -0.571465 -0.684115   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.227050  0.130983  0.041438   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26395  0.041637  0.092217  0.140510  ... -0.336787 -0.306774 -0.280607   \n",
       "26396  0.092217  0.140510  0.188025  ... -0.306774 -0.280607 -0.269843   \n",
       "26397  0.140510  0.188025  0.240939  ... -0.280607 -0.269843 -0.260062   \n",
       "26398  0.188025  0.240939  0.294399  ... -0.269843 -0.260062 -0.229981   \n",
       "26399  0.240939  0.294399  0.340346  ... -0.260062 -0.229981 -0.167654   \n",
       "\n",
       "             79        80        81        82        83        84  labels  \n",
       "0      0.595845  0.661691  0.702932  0.708613  0.682564  0.637765    deep  \n",
       "1     -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654    deep  \n",
       "2      1.049543  1.024204  0.954716  0.844505  0.702445  0.541555    deep  \n",
       "3     -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059    deep  \n",
       "4     -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270    deep  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "26395 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372   quick  \n",
       "26396 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958   quick  \n",
       "26397 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209   quick  \n",
       "26398 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014   quick  \n",
       "26399 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418   quick  \n",
       "\n",
       "[26400 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8bf54a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa8bf54a",
    "outputId": "f4f08ec0-c57c-4ca4-c131-af36d583eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X have a null? \tFalse\n",
      "Y have a null? \tFalse\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "# Check if the data do not have any NULL \n",
    "print(\"X have a null? \\t{}\".format(X.isnull().values.any()))\n",
    "print(\"Y have a null? \\t{}\".format(Y.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa06c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0fa06c9f",
    "outputId": "35e89335-323c-4d86-9678-f74d1acf0b10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332737</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325687</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.407344</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322969</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345803</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26400 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26395 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "26396 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "26397 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "26398 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "26399 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        75        76        77  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.332737  0.391514  0.452677   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.325687  0.138731 -0.053860   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.902226  0.947940  0.996154   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.407344 -0.478218 -0.571465   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.322969  0.227050  0.130983   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26395  0.041637  0.092217  0.140510  ... -0.345803 -0.336787 -0.306774   \n",
       "26396  0.092217  0.140510  0.188025  ... -0.336787 -0.306774 -0.280607   \n",
       "26397  0.140510  0.188025  0.240939  ... -0.306774 -0.280607 -0.269843   \n",
       "26398  0.188025  0.240939  0.294399  ... -0.280607 -0.269843 -0.260062   \n",
       "26399  0.240939  0.294399  0.340346  ... -0.269843 -0.260062 -0.229981   \n",
       "\n",
       "             78        79        80        81        82        83        84  \n",
       "0      0.521407  0.595845  0.661691  0.702932  0.708613  0.682564  0.637765  \n",
       "1     -0.241691 -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654  \n",
       "2      1.035743  1.049543  1.024204  0.954716  0.844505  0.702445  0.541555  \n",
       "3     -0.684115 -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059  \n",
       "4      0.041438 -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "26395 -0.280607 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  \n",
       "26396 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  \n",
       "26397 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  \n",
       "26398 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  \n",
       "26399 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418  \n",
       "\n",
       "[26400 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b3592e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b3592e",
    "outputId": "14191ef1-d3ce-4982-83b9-ecf9bcf5312d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        19734\n",
       "quick          2667\n",
       "hold           2133\n",
       "deep           1066\n",
       "deep_quick      800\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b0906",
   "metadata": {
    "id": "4c2b0906"
   },
   "source": [
    "### Program Starting\n",
    "# PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f193",
   "metadata": {
    "id": "0723f193"
   },
   "source": [
    "## Hot Encoded The Label Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0322a049",
   "metadata": {
    "id": "0322a049"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46851a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46851a41",
    "outputId": "f92ebfa5-d6db-4fb0-f31a-081e94150d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee49ad",
   "metadata": {},
   "source": [
    "## Extract using MFCC (if you not want, just skip this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05580da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_mfcc(df_, sr=60, n_mfcc=85):\n",
    "  df_mfcc = []\n",
    "  with tqdm(total=df_.shape[0]) as pbar: \n",
    "      for i,row in df_.iterrows():\n",
    "        pbar.update(1)\n",
    "        y = np.array(row).astype(np.float32)\n",
    "        #print(\"y : {}\".format(y))\n",
    "        #print(\"y shape: {}\".format(np.array(y).shape))\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        #print(\"mfccs before squeze : {}\".format(mfccs))\n",
    "        #print(\"mfccs before squeze : {}\".format(np.array(mfccs).shape))\n",
    "        \n",
    "        mfccs = np.squeeze(mfccs, axis=1)\n",
    "        #print(\"mfccs after squeze: {}\".format(mfccs))\n",
    "        #print(\"mfccs after squeze : {}\".format(np.array(mfccs).shape))\n",
    "        \n",
    "        df_mfcc.append([*mfccs])\n",
    "        #print(\"df_mfcc : {}\".format(df_mfcc))\n",
    "        #print(\"df_mfcc shape : {}\".format(np.array(df_mfcc).shape))\n",
    "      df_mfcc = pd.DataFrame(df_mfcc, columns=[*np.arange(0,85)])\n",
    "  return df_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_mfcc(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279137d",
   "metadata": {
    "id": "5279137d"
   },
   "source": [
    "## Scale The Training Data (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0513ed4",
   "metadata": {
    "id": "b0513ed4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be3b8",
   "metadata": {
    "id": "9b1be3b8"
   },
   "source": [
    "## Reshaping The Training Data to 3-Dimensional Numpy Array\n",
    "### STRUCTURE : (batch_size, timestep, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0456d564",
   "metadata": {
    "id": "0456d564"
   },
   "outputs": [],
   "source": [
    "timestep = 5\n",
    "X = np.reshape(X, (X.shape[0], int(85/timestep), timestep))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P5yzJzU7qvp7",
   "metadata": {
    "id": "P5yzJzU7qvp7"
   },
   "source": [
    "## Train Test Split (80% training 20% Testing)\n",
    "### REMEMBER : seed must same (random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "QIpR2SpYqxYh",
   "metadata": {
    "id": "QIpR2SpYqxYh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, hot_y, test_size=.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0ca7",
   "metadata": {
    "id": "bcbc0ca7"
   },
   "source": [
    "# PART 2 : Building The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d100f8a8",
   "metadata": {
    "id": "d100f8a8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFcb5tIpis9h",
   "metadata": {
    "id": "oFcb5tIpis9h"
   },
   "source": [
    "## Creating Layer of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc7f5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Model Structure\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam()\n",
    "_loss = \"categorical_crossentropy\"\n",
    "_metric = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfbb09d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfbb09d5",
    "outputId": "10305db0-f336-4336-d54f-4a100ebc1152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 17, 60)            15840     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 17, 60)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 17, 60)            29040     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 60)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 60)                29040     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 305       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,225\n",
      "Trainable params: 74,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "# first layer\n",
    "classifier.add(LSTM(units=60, return_sequences=True, input_shape=(17, 5)))\n",
    "classifier.add(Dropout(0.2))    # Ignore 20% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored) \n",
    "\n",
    "# second layer\n",
    "classifier.add(LSTM(units=60, return_sequences=True))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# third layer\n",
    "# classifier.add(LSTM(units=20, return_sequences=True))\n",
    "# classifier.add(Dropout(0.2))\n",
    "\n",
    "# fourth layer\n",
    "classifier.add(LSTM(units=60))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# last layer\n",
    "classifier.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "# Compile\n",
    "classifier.compile(optimizer=_optimizer, loss=_loss, metrics=_metric)\n",
    "\n",
    "# Plot Summary of Model\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHxGBbTjiOO",
   "metadata": {
    "id": "gYHxGBbTjiOO"
   },
   "source": [
    "# PART 3 : Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ngysebSjIBl",
   "metadata": {
    "id": "3ngysebSjIBl"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7wCqc9xqG8l7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wCqc9xqG8l7",
    "outputId": "db6e0034-41fa-4a02-a6d8-ae353c0b1a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "660/660 [==============================] - 16s 19ms/step - loss: 0.7114 - accuracy: 0.7672 - val_loss: 0.6455 - val_accuracy: 0.7680\n",
      "Epoch 2/15\n",
      "660/660 [==============================] - 13s 19ms/step - loss: 0.5988 - accuracy: 0.7793 - val_loss: 0.5158 - val_accuracy: 0.8085\n",
      "Epoch 3/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.4897 - accuracy: 0.8097 - val_loss: 0.4167 - val_accuracy: 0.8458\n",
      "Epoch 4/15\n",
      "660/660 [==============================] - 12s 19ms/step - loss: 0.3744 - accuracy: 0.8607 - val_loss: 0.3184 - val_accuracy: 0.8922\n",
      "Epoch 5/15\n",
      "660/660 [==============================] - 12s 19ms/step - loss: 0.2801 - accuracy: 0.9029 - val_loss: 0.2587 - val_accuracy: 0.9144\n",
      "Epoch 6/15\n",
      "660/660 [==============================] - 12s 19ms/step - loss: 0.2103 - accuracy: 0.9297 - val_loss: 0.1634 - val_accuracy: 0.9491\n",
      "Epoch 7/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.1630 - accuracy: 0.9461 - val_loss: 0.1379 - val_accuracy: 0.9568\n",
      "Epoch 8/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.1359 - accuracy: 0.9569 - val_loss: 0.1225 - val_accuracy: 0.9616\n",
      "Epoch 9/15\n",
      "660/660 [==============================] - 12s 19ms/step - loss: 0.1175 - accuracy: 0.9642 - val_loss: 0.0960 - val_accuracy: 0.9725\n",
      "Epoch 10/15\n",
      "660/660 [==============================] - 12s 19ms/step - loss: 0.0993 - accuracy: 0.9703 - val_loss: 0.0891 - val_accuracy: 0.9735\n",
      "Epoch 11/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.0882 - accuracy: 0.9749 - val_loss: 0.0834 - val_accuracy: 0.9801\n",
      "Epoch 12/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.0825 - accuracy: 0.9765 - val_loss: 0.0709 - val_accuracy: 0.9797\n",
      "Epoch 13/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.0772 - accuracy: 0.9776 - val_loss: 0.0854 - val_accuracy: 0.9752\n",
      "Epoch 14/15\n",
      "660/660 [==============================] - 12s 18ms/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 0.0651 - val_accuracy: 0.9809\n",
      "Epoch 15/15\n",
      "660/660 [==============================] - 12s 19ms/step - loss: 0.0672 - accuracy: 0.9809 - val_loss: 0.0754 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edc9f6c9a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting for training arguments (epoch, batch_size)\n",
    "ep = 15        # epoch\n",
    "bt = 32        # batch_size\n",
    "# Without Cross-Validation\n",
    "classifier.fit(X_train, Y_train, epochs=ep, batch_size=bt, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592adcf7",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "GD1YXs9fGzd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD1YXs9fGzd4",
    "outputId": "9f855f48-59ce-43d4-d11f-e4b5ecf422cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 1s 8ms/step - loss: 0.0754 - accuracy: 0.9761\n",
      "Accuracy \t: 97.61\n",
      "Loss \t\t: 7.54\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = classifier.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "_qkQtuYLIsTg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qkQtuYLIsTg",
    "outputId": "30b8cd45-0234-48c6-a659-72a93466d297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "t2U4bAnrIzCR",
   "metadata": {
    "id": "t2U4bAnrIzCR"
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, axis=1)\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13e6b",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Om9OAOGfplSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Om9OAOGfplSe",
    "outputId": "3e40fd9c-b99f-43b1-e20f-89472d8ead74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Greens)\n",
    "\n",
    "# Add labels to the plot\n",
    "tick_marks = np.arange(len(conf_matrix))\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Add values to the plot\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yehFnOBDjZcJ",
   "metadata": {
    "id": "yehFnOBDjZcJ"
   },
   "source": [
    "## Saving the model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BW3wgAyQjoF9",
   "metadata": {
    "id": "BW3wgAyQjoF9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# saving the model\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\", _optimizer)\n",
    "classifier.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vFkQEQYVj5sb",
   "metadata": {
    "id": "vFkQEQYVj5sb"
   },
   "source": [
    "# PART 4 : Testing the Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xGVuh9xGmzuj",
   "metadata": {
    "id": "xGVuh9xGmzuj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# _optimizer = \"Adam\"\n",
    "filename = \"{}\\\\{}\\\\{}.h5\".format(os.getcwd(), \"MODELS\\\\[3-layer] - 3L1\", _optimizer)\n",
    "\n",
    "# load model\n",
    "loaded_model = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cf7c1",
   "metadata": {
    "id": "1xjvuy1flJtr"
   },
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be023c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = loaded_model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04b558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yehFnOBDjZcJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
