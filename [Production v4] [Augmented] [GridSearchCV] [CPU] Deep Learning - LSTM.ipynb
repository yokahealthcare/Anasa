{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9576fde0",
   "metadata": {
    "id": "9576fde0"
   },
   "source": [
    "# BREATHING WAVE\n",
    "## DEEP LEARNING - LSTM\n",
    "### 04 March 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cfa282",
   "metadata": {
    "id": "07cfa282"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(\"breathing_waveform_data.csv\").iloc[:, :-1] # get rid of last column (\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa06c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0fa06c9f",
    "outputId": "35e89335-323c-4d86-9678-f74d1acf0b10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.483309</td>\n",
       "      <td>0.459790</td>\n",
       "      <td>0.431024</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.066060</td>\n",
       "      <td>-0.083445</td>\n",
       "      <td>-0.247221</td>\n",
       "      <td>-0.409374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>0.521407</td>\n",
       "      <td>0.595845</td>\n",
       "      <td>0.661691</td>\n",
       "      <td>0.702932</td>\n",
       "      <td>0.708613</td>\n",
       "      <td>0.682564</td>\n",
       "      <td>0.637765</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.044518</td>\n",
       "      <td>-1.935588</td>\n",
       "      <td>-1.808629</td>\n",
       "      <td>-1.667919</td>\n",
       "      <td>-1.513497</td>\n",
       "      <td>-1.348760</td>\n",
       "      <td>-1.171044</td>\n",
       "      <td>-0.972509</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.547793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138731</td>\n",
       "      <td>-0.053860</td>\n",
       "      <td>-0.241691</td>\n",
       "      <td>-0.417603</td>\n",
       "      <td>-0.582320</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>-0.889731</td>\n",
       "      <td>-1.037066</td>\n",
       "      <td>-1.174654</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.213535</td>\n",
       "      <td>-1.269056</td>\n",
       "      <td>-1.323306</td>\n",
       "      <td>-1.375251</td>\n",
       "      <td>-1.430062</td>\n",
       "      <td>-1.485479</td>\n",
       "      <td>-1.529200</td>\n",
       "      <td>-1.557172</td>\n",
       "      <td>-1.574662</td>\n",
       "      <td>-1.575457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947940</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.035743</td>\n",
       "      <td>1.049543</td>\n",
       "      <td>1.024204</td>\n",
       "      <td>0.954716</td>\n",
       "      <td>0.844505</td>\n",
       "      <td>0.702445</td>\n",
       "      <td>0.541555</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.914806</td>\n",
       "      <td>-0.887726</td>\n",
       "      <td>-0.856065</td>\n",
       "      <td>-0.823527</td>\n",
       "      <td>-0.794551</td>\n",
       "      <td>-0.768074</td>\n",
       "      <td>-0.740895</td>\n",
       "      <td>-0.713364</td>\n",
       "      <td>-0.685445</td>\n",
       "      <td>-0.652020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.478218</td>\n",
       "      <td>-0.571465</td>\n",
       "      <td>-0.684115</td>\n",
       "      <td>-0.817078</td>\n",
       "      <td>-0.966231</td>\n",
       "      <td>-1.122537</td>\n",
       "      <td>-1.264759</td>\n",
       "      <td>-1.376908</td>\n",
       "      <td>-1.461059</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.547469</td>\n",
       "      <td>-1.458818</td>\n",
       "      <td>-1.362120</td>\n",
       "      <td>-1.264829</td>\n",
       "      <td>-1.164948</td>\n",
       "      <td>-1.060064</td>\n",
       "      <td>-0.954496</td>\n",
       "      <td>-0.849448</td>\n",
       "      <td>-0.742812</td>\n",
       "      <td>-0.636614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227050</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.106152</td>\n",
       "      <td>-0.163048</td>\n",
       "      <td>-0.210926</td>\n",
       "      <td>-0.253102</td>\n",
       "      <td>-0.290270</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26395</th>\n",
       "      <td>-0.152463</td>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336787</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26396</th>\n",
       "      <td>-0.164723</td>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306774</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>-0.165409</td>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280607</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26398</th>\n",
       "      <td>-0.152623</td>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269843</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26399</th>\n",
       "      <td>-0.118115</td>\n",
       "      <td>-0.066218</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>0.140510</td>\n",
       "      <td>0.188025</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.294399</td>\n",
       "      <td>0.340346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260062</td>\n",
       "      <td>-0.229981</td>\n",
       "      <td>-0.167654</td>\n",
       "      <td>-0.082300</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.089958</td>\n",
       "      <td>0.179209</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.343418</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26400 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.483309  0.459790  0.431024  0.376565  0.295734  0.193290  0.066060   \n",
       "1     -2.044518 -1.935588 -1.808629 -1.667919 -1.513497 -1.348760 -1.171044   \n",
       "2     -1.213535 -1.269056 -1.323306 -1.375251 -1.430062 -1.485479 -1.529200   \n",
       "3     -0.914806 -0.887726 -0.856065 -0.823527 -0.794551 -0.768074 -0.740895   \n",
       "4     -1.547469 -1.458818 -1.362120 -1.264829 -1.164948 -1.060064 -0.954496   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26395 -0.152463 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253   \n",
       "26396 -0.164723 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637   \n",
       "26397 -0.165409 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217   \n",
       "26398 -0.152623 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510   \n",
       "26399 -0.118115 -0.066218 -0.010253  0.041637  0.092217  0.140510  0.188025   \n",
       "\n",
       "              7         8         9  ...        76        77        78  \\\n",
       "0     -0.083445 -0.247221 -0.409374  ...  0.391514  0.452677  0.521407   \n",
       "1     -0.972509 -0.759554 -0.547793  ...  0.138731 -0.053860 -0.241691   \n",
       "2     -1.557172 -1.574662 -1.575457  ...  0.947940  0.996154  1.035743   \n",
       "3     -0.713364 -0.685445 -0.652020  ... -0.478218 -0.571465 -0.684115   \n",
       "4     -0.849448 -0.742812 -0.636614  ...  0.227050  0.130983  0.041438   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "26395  0.041637  0.092217  0.140510  ... -0.336787 -0.306774 -0.280607   \n",
       "26396  0.092217  0.140510  0.188025  ... -0.306774 -0.280607 -0.269843   \n",
       "26397  0.140510  0.188025  0.240939  ... -0.280607 -0.269843 -0.260062   \n",
       "26398  0.188025  0.240939  0.294399  ... -0.269843 -0.260062 -0.229981   \n",
       "26399  0.240939  0.294399  0.340346  ... -0.260062 -0.229981 -0.167654   \n",
       "\n",
       "             79        80        81        82        83        84  labels  \n",
       "0      0.595845  0.661691  0.702932  0.708613  0.682564  0.637765    deep  \n",
       "1     -0.417603 -0.582320 -0.738485 -0.889731 -1.037066 -1.174654    deep  \n",
       "2      1.049543  1.024204  0.954716  0.844505  0.702445  0.541555    deep  \n",
       "3     -0.817078 -0.966231 -1.122537 -1.264759 -1.376908 -1.461059    deep  \n",
       "4     -0.038034 -0.106152 -0.163048 -0.210926 -0.253102 -0.290270    deep  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "26395 -0.269843 -0.260062 -0.229981 -0.167654 -0.082300  0.004372   quick  \n",
       "26396 -0.260062 -0.229981 -0.167654 -0.082300  0.004372  0.089958   quick  \n",
       "26397 -0.229981 -0.167654 -0.082300  0.004372  0.089958  0.179209   quick  \n",
       "26398 -0.167654 -0.082300  0.004372  0.089958  0.179209  0.264014   quick  \n",
       "26399 -0.082300  0.004372  0.089958  0.179209  0.264014  0.343418   quick  \n",
       "\n",
       "[26400 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5efc4d-1b6c-4706-9bd6-96fed498677c",
   "metadata": {},
   "source": [
    "## Augmented Data (UP & DOWN 0.01)\n",
    "### Current Shape now  : 26400 x 3 = 79200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331e6631-aee2-4ee0-b7b5-70286a205dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = df\n",
    "down = df\n",
    "up.iloc[:, :-1] += 0.01\n",
    "down.iloc[:, :-1] -= 0.01\n",
    "df = pd.concat([df, up, down], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5f7ddb-b29f-4acf-9b13-5ea3ebb1d3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79200, 86)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa8bf54a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa8bf54a",
    "outputId": "f4f08ec0-c57c-4ca4-c131-af36d583eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X have a null? \tFalse\n",
      "Y have a null? \tFalse\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "# Check if the data do not have any NULL \n",
    "print(\"X have a null? \\t{}\".format(X.isnull().values.any()))\n",
    "print(\"Y have a null? \\t{}\".format(Y.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b3592e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1b3592e",
    "outputId": "14191ef1-d3ce-4982-83b9-ecf9bcf5312d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        59202\n",
       "quick          8001\n",
       "hold           6399\n",
       "deep           3198\n",
       "deep_quick     2400\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8299c60",
   "metadata": {},
   "source": [
    "## Fix Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85e7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 21\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b0906",
   "metadata": {
    "id": "4c2b0906"
   },
   "source": [
    "### Program Starting\n",
    "# PART 1 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f193",
   "metadata": {
    "id": "0723f193"
   },
   "source": [
    "## Hot Encoded The Label Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0322a049",
   "metadata": {
    "id": "0322a049"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# encode class values as integers [0,0,0,0,0,0,0,1,1,1,1,1,2,2,2,2]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "hot_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46851a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46851a41",
    "outputId": "f92ebfa5-d6db-4fb0-f31a-081e94150d10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279137d",
   "metadata": {
    "id": "5279137d"
   },
   "source": [
    "## Scale The Training Data (STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0513ed4",
   "metadata": {
    "id": "b0513ed4"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1be3b8",
   "metadata": {
    "id": "9b1be3b8"
   },
   "source": [
    "## Reshaping The Training Data to 3-Dimensional Numpy Array\n",
    "### STRUCTURE : (batch_size, timestep, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0456d564",
   "metadata": {
    "id": "0456d564"
   },
   "outputs": [],
   "source": [
    "feature = 5\n",
    "X = np.reshape(X, (X.shape[0], int(85/feature), feature))\n",
    "# (26400, 17, 5)\n",
    "# 5 indicator will be used per sequence/timestep per sample/row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699b14e",
   "metadata": {},
   "source": [
    "### Split the training data and testing data 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ace2d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, hot_y, test_size=.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc0ca7",
   "metadata": {
    "id": "bcbc0ca7"
   },
   "source": [
    "# PART 2 : Building The RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d100f8a8",
   "metadata": {
    "id": "d100f8a8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFcb5tIpis9h",
   "metadata": {
    "id": "oFcb5tIpis9h"
   },
   "source": [
    "## Creating Layer of RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7f5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Model Structure\n",
    "from keras.optimizers import Adam\n",
    "_optimizer = Adam()\n",
    "_loss = \"categorical_crossentropy\"\n",
    "_metric = [\"accuracy\"]\n",
    "\n",
    "best_dropout_rate=0.3\n",
    "best_init_mode='he_uniform'\n",
    "best_init_recurrent='orthogonal'\n",
    "best_init_units=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbb09d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfbb09d5",
    "outputId": "10305db0-f336-4336-d54f-4a100ebc1152"
   },
   "outputs": [],
   "source": [
    "def create_model(dropout_rate=best_dropout_rate, init_mode=best_init_mode, init_recurrent=best_init_recurrent, init_units=best_init_units):\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # first layer\n",
    "    classifier.add(LSTM(units=init_units, kernel_initializer=init_mode, recurrent_initializer=init_recurrent, return_sequences=True, input_shape=(17, 5)))\n",
    "    classifier.add(Dropout(dropout_rate))    # Ignore xx% of the neuron (ex. 50 * 20% = 10 neuoron will be ignored) \n",
    "\n",
    "    # second layer\n",
    "    classifier.add(LSTM(units=init_units, return_sequences=True))\n",
    "    classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # third layer\n",
    "    # classifier.add(LSTM(units=20, return_sequences=True))\n",
    "    # classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # fourth layer\n",
    "    classifier.add(LSTM(units=init_units))\n",
    "    classifier.add(Dropout(dropout_rate))\n",
    "\n",
    "    # last layer\n",
    "    classifier.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "    # Compile\n",
    "    classifier.compile(optimizer=_optimizer, loss=_loss, metrics=_metric)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gYHxGBbTjiOO",
   "metadata": {
    "id": "gYHxGBbTjiOO"
   },
   "source": [
    "# PART 3 : Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58cdf8",
   "metadata": {},
   "source": [
    "## Setting up the GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12081268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "\n",
    "print(f\"Number of CPU cores: {cpu_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803e1b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84434c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1980/1980 [==============================] - 20s 9ms/step - loss: 0.4738 - accuracy: 0.8287\n",
      "Epoch 2/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.2508 - accuracy: 0.9107\n",
      "Epoch 3/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.1417 - accuracy: 0.9536\n",
      "Epoch 4/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0951 - accuracy: 0.9718\n",
      "Epoch 5/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0785 - accuracy: 0.9780\n",
      "Epoch 6/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0644 - accuracy: 0.9820\n",
      "Epoch 7/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0588 - accuracy: 0.9838\n",
      "Epoch 8/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0533 - accuracy: 0.9851\n",
      "Epoch 9/20\n",
      "1980/1980 [==============================] - 19s 9ms/step - loss: 0.0460 - accuracy: 0.9875\n",
      "Epoch 10/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0426 - accuracy: 0.9883\n",
      "Epoch 11/20\n",
      "1980/1980 [==============================] - 19s 9ms/step - loss: 0.0400 - accuracy: 0.9883\n",
      "Epoch 12/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0327 - accuracy: 0.9906\n",
      "Epoch 13/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0326 - accuracy: 0.9908\n",
      "Epoch 14/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0290 - accuracy: 0.9915\n",
      "Epoch 15/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0259 - accuracy: 0.9919\n",
      "Epoch 16/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 17/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0204 - accuracy: 0.9933\n",
      "Epoch 18/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0207 - accuracy: 0.9938\n",
      "Epoch 19/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0199 - accuracy: 0.9939\n",
      "Epoch 20/20\n",
      "1980/1980 [==============================] - 18s 9ms/step - loss: 0.0167 - accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "classifier = create_model()\n",
    "\n",
    "with tf.device('/device:CPU:0'):\n",
    "    classifier.fit(X_train, Y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592adcf7",
   "metadata": {},
   "source": [
    "# PART 4 : Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GD1YXs9fGzd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD1YXs9fGzd4",
    "outputId": "9f855f48-59ce-43d4-d11f-e4b5ecf422cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/495 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Accuracy \t: 99.74\n",
      "Loss \t\t: 0.68\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "score = classifier.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "_qkQtuYLIsTg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qkQtuYLIsTg",
    "outputId": "30b8cd45-0234-48c6-a659-72a93466d297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/495 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "t2U4bAnrIzCR",
   "metadata": {
    "id": "t2U4bAnrIzCR"
   },
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, axis=1)\n",
    "y_pred = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13e6b",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "Om9OAOGfplSe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Om9OAOGfplSe",
    "outputId": "3e40fd9c-b99f-43b1-e20f-89472d8ead74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(conf_matrix, cmap=plt.cm.Greens)\n",
    "\n",
    "# Add labels to the plot\n",
    "tick_marks = np.arange(len(conf_matrix))\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "# Add values to the plot\n",
    "for i in range(len(conf_matrix)):\n",
    "    for j in range(len(conf_matrix)):\n",
    "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yehFnOBDjZcJ",
   "metadata": {
    "id": "yehFnOBDjZcJ"
   },
   "source": [
    "## Saving the model into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "BW3wgAyQjoF9",
   "metadata": {
    "id": "BW3wgAyQjoF9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Saving the model\n",
    "filename = \"C:\\\\Users\\\\IoT-Lab\\\\Documents\\\\!Erwin Yonata\\\\Anasa\\\\MODELS\\\\[3-layer] - 3L1\\\\CV\\\\GridSearchCV\\\\best_param_model.h5\"\n",
    "classifier.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vFkQEQYVj5sb",
   "metadata": {
    "id": "vFkQEQYVj5sb"
   },
   "source": [
    "# PART 5 : Testing the Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "xGVuh9xGmzuj",
   "metadata": {
    "id": "xGVuh9xGmzuj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "filename = \"C:\\\\Users\\\\IoT-Lab\\\\Documents\\\\!Erwin Yonata\\\\Anasa\\\\MODELS\\\\[3-layer] - 3L1\\\\CV\\\\GridSearchCV\\\\best_param_model.h5\"\n",
    "\n",
    "# load model\n",
    "loaded_model = load_model(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cf7c1",
   "metadata": {
    "id": "1xjvuy1flJtr"
   },
   "source": [
    "## evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be023c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495/495 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9974\n",
      "Accuracy \t: 99.74\n",
      "Loss \t\t: 0.68\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_test, Y_test)\n",
    "print(\"Accuracy \\t: {:.2f}\".format(score[1]*100))\n",
    "print(\"Loss \\t\\t: {:.2f}\".format(score[0]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yehFnOBDjZcJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
